{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using MPS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='mps')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader  \n",
    "\n",
    "# Check that MPS is available\n",
    "\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\n",
    "            \"MPS not available because the current PyTorch install was not \"\n",
    "            \"built with MPS enabled.\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "            \"and/or you do not have an MPS-enabled device on this machine.\"\n",
    "        )\n",
    "    mps_device = None\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "\n",
    "if mps_device is not None:\n",
    "    device = mps_device\n",
    "    print(\"Using MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 8.4759\n",
      "Epoch 1, Batch 200, Loss: 2.6670\n",
      "Epoch 1, Batch 300, Loss: 2.4985\n",
      "Epoch 1, Batch 400, Loss: 2.4261\n",
      "Epoch 1, Batch 500, Loss: 2.3340\n",
      "Epoch 1, Batch 600, Loss: 2.3195\n",
      "Epoch 1, Batch 700, Loss: 2.2786\n",
      "Epoch 1, Batch 800, Loss: 2.2012\n",
      "Epoch 1, Batch 900, Loss: 2.2753\n",
      "Epoch 1, Batch 1000, Loss: 2.2339\n",
      "Epoch 1, Batch 1100, Loss: 2.1768\n",
      "Epoch 1, Batch 1200, Loss: 2.1342\n",
      "Epoch 1, Batch 1300, Loss: 2.0827\n",
      "Epoch 1, Batch 1400, Loss: 2.0981\n",
      "Epoch 1, Batch 1500, Loss: 1.9979\n",
      "Epoch 1, Batch 1600, Loss: 2.0325\n",
      "Epoch 1, Batch 1700, Loss: 1.9884\n",
      "Epoch 1, Batch 1800, Loss: 2.0070\n",
      "Epoch 1, Batch 1900, Loss: 1.9676\n",
      "Epoch 1, Batch 2000, Loss: 1.8557\n",
      "Epoch 1, Batch 2100, Loss: 1.9369\n",
      "Epoch 1, Batch 2200, Loss: 1.9248\n",
      "Epoch 1, Batch 2300, Loss: 1.8250\n",
      "Epoch 1, Batch 2400, Loss: 1.8778\n",
      "Epoch 1, Batch 2500, Loss: 1.8369\n",
      "Epoch 1, Batch 2600, Loss: 1.8900\n",
      "Epoch 1, Batch 2700, Loss: 1.8264\n",
      "Epoch 1, Batch 2800, Loss: 1.7919\n",
      "Epoch 1, Batch 2900, Loss: 1.7738\n",
      "Epoch 2, Batch 100, Loss: 1.7745\n",
      "Epoch 2, Batch 200, Loss: 1.7632\n",
      "Epoch 2, Batch 300, Loss: 1.7263\n",
      "Epoch 2, Batch 400, Loss: 1.7077\n",
      "Epoch 2, Batch 500, Loss: 1.6393\n",
      "Epoch 2, Batch 600, Loss: 1.6624\n",
      "Epoch 2, Batch 700, Loss: 1.7347\n",
      "Epoch 2, Batch 800, Loss: 1.7236\n",
      "Epoch 2, Batch 900, Loss: 1.7491\n",
      "Epoch 2, Batch 1000, Loss: 1.7021\n",
      "Epoch 2, Batch 1100, Loss: 1.6576\n",
      "Epoch 2, Batch 1200, Loss: 1.6116\n",
      "Epoch 2, Batch 1300, Loss: 1.6071\n",
      "Epoch 2, Batch 1400, Loss: 1.6319\n",
      "Epoch 2, Batch 1500, Loss: 1.5939\n",
      "Epoch 2, Batch 1600, Loss: 1.6119\n",
      "Epoch 2, Batch 1700, Loss: 1.5680\n",
      "Epoch 2, Batch 1800, Loss: 1.4935\n",
      "Epoch 2, Batch 1900, Loss: 1.5524\n",
      "Epoch 2, Batch 2000, Loss: 1.5379\n",
      "Epoch 2, Batch 2100, Loss: 1.6186\n",
      "Epoch 2, Batch 2200, Loss: 1.5822\n",
      "Epoch 2, Batch 2300, Loss: 1.5359\n",
      "Epoch 2, Batch 2400, Loss: 1.5133\n",
      "Epoch 2, Batch 2500, Loss: 1.5554\n",
      "Epoch 2, Batch 2600, Loss: 1.5338\n",
      "Epoch 2, Batch 2700, Loss: 1.4727\n",
      "Epoch 2, Batch 2800, Loss: 1.5193\n",
      "Epoch 2, Batch 2900, Loss: 1.4696\n",
      "Epoch 3, Batch 100, Loss: 1.4417\n",
      "Epoch 3, Batch 200, Loss: 1.4499\n",
      "Epoch 3, Batch 300, Loss: 1.4396\n",
      "Epoch 3, Batch 400, Loss: 1.4241\n",
      "Epoch 3, Batch 500, Loss: 1.4263\n",
      "Epoch 3, Batch 600, Loss: 1.4266\n",
      "Epoch 3, Batch 700, Loss: 1.4368\n",
      "Epoch 3, Batch 800, Loss: 1.4134\n",
      "Epoch 3, Batch 900, Loss: 1.4793\n",
      "Epoch 3, Batch 1000, Loss: 1.4256\n",
      "Epoch 3, Batch 1100, Loss: 1.3810\n",
      "Epoch 3, Batch 1200, Loss: 1.4283\n",
      "Epoch 3, Batch 1300, Loss: 1.4184\n",
      "Epoch 3, Batch 1400, Loss: 1.3497\n",
      "Epoch 3, Batch 1500, Loss: 1.3907\n",
      "Epoch 3, Batch 1600, Loss: 1.4331\n",
      "Epoch 3, Batch 1700, Loss: 1.4334\n",
      "Epoch 3, Batch 1800, Loss: 1.4217\n",
      "Epoch 3, Batch 1900, Loss: 1.4539\n",
      "Epoch 3, Batch 2000, Loss: 1.4047\n",
      "Epoch 3, Batch 2100, Loss: 1.4223\n",
      "Epoch 3, Batch 2200, Loss: 1.3872\n",
      "Epoch 3, Batch 2300, Loss: 1.3882\n",
      "Epoch 3, Batch 2400, Loss: 1.3988\n",
      "Epoch 3, Batch 2500, Loss: 1.4102\n",
      "Epoch 3, Batch 2600, Loss: 1.3515\n",
      "Epoch 3, Batch 2700, Loss: 1.3810\n",
      "Epoch 3, Batch 2800, Loss: 1.3990\n",
      "Epoch 3, Batch 2900, Loss: 1.3558\n",
      "Epoch 4, Batch 100, Loss: 1.3504\n",
      "Epoch 4, Batch 200, Loss: 1.3520\n",
      "Epoch 4, Batch 300, Loss: 1.3114\n",
      "Epoch 4, Batch 400, Loss: 1.3200\n",
      "Epoch 4, Batch 500, Loss: 1.3113\n",
      "Epoch 4, Batch 600, Loss: 1.3349\n",
      "Epoch 4, Batch 700, Loss: 1.3075\n",
      "Epoch 4, Batch 800, Loss: 1.2628\n",
      "Epoch 4, Batch 900, Loss: 1.3030\n",
      "Epoch 4, Batch 1000, Loss: 1.2779\n",
      "Epoch 4, Batch 1100, Loss: 1.3228\n",
      "Epoch 4, Batch 1200, Loss: 1.2976\n",
      "Epoch 4, Batch 1300, Loss: 1.2650\n",
      "Epoch 4, Batch 1400, Loss: 1.3014\n",
      "Epoch 4, Batch 1500, Loss: 1.2684\n",
      "Epoch 4, Batch 1600, Loss: 1.3316\n",
      "Epoch 4, Batch 1700, Loss: 1.3033\n",
      "Epoch 4, Batch 1800, Loss: 1.2634\n",
      "Epoch 4, Batch 1900, Loss: 1.2515\n",
      "Epoch 4, Batch 2000, Loss: 1.3008\n",
      "Epoch 4, Batch 2100, Loss: 1.2997\n",
      "Epoch 4, Batch 2200, Loss: 1.2501\n",
      "Epoch 4, Batch 2300, Loss: 1.2995\n",
      "Epoch 4, Batch 2400, Loss: 1.2974\n",
      "Epoch 4, Batch 2500, Loss: 1.2719\n",
      "Epoch 4, Batch 2600, Loss: 1.2834\n",
      "Epoch 4, Batch 2700, Loss: 1.2529\n",
      "Epoch 4, Batch 2800, Loss: 1.3306\n",
      "Epoch 4, Batch 2900, Loss: 1.3096\n",
      "Epoch 5, Batch 100, Loss: 1.1576\n",
      "Epoch 5, Batch 200, Loss: 1.1630\n",
      "Epoch 5, Batch 300, Loss: 1.2058\n",
      "Epoch 5, Batch 400, Loss: 1.1938\n",
      "Epoch 5, Batch 500, Loss: 1.1813\n",
      "Epoch 5, Batch 600, Loss: 1.2575\n",
      "Epoch 5, Batch 700, Loss: 1.2156\n",
      "Epoch 5, Batch 800, Loss: 1.2296\n",
      "Epoch 5, Batch 900, Loss: 1.1551\n",
      "Epoch 5, Batch 1000, Loss: 1.2217\n",
      "Epoch 5, Batch 1100, Loss: 1.1306\n",
      "Epoch 5, Batch 1200, Loss: 1.1772\n",
      "Epoch 5, Batch 1300, Loss: 1.1707\n",
      "Epoch 5, Batch 1400, Loss: 1.2273\n",
      "Epoch 5, Batch 1500, Loss: 1.2302\n",
      "Epoch 5, Batch 1600, Loss: 1.1908\n",
      "Epoch 5, Batch 1700, Loss: 1.1955\n",
      "Epoch 5, Batch 1800, Loss: 1.2027\n",
      "Epoch 5, Batch 1900, Loss: 1.1987\n",
      "Epoch 5, Batch 2000, Loss: 1.1750\n",
      "Epoch 5, Batch 2100, Loss: 1.2206\n",
      "Epoch 5, Batch 2200, Loss: 1.1982\n",
      "Epoch 5, Batch 2300, Loss: 1.2122\n",
      "Epoch 5, Batch 2400, Loss: 1.2017\n",
      "Epoch 5, Batch 2500, Loss: 1.1974\n",
      "Epoch 5, Batch 2600, Loss: 1.1942\n",
      "Epoch 5, Batch 2700, Loss: 1.2002\n",
      "Epoch 5, Batch 2800, Loss: 1.1830\n",
      "Epoch 5, Batch 2900, Loss: 1.2234\n",
      "CPU times: user 51.7 s, sys: 7.3 s, total: 59.1 s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Define the dataset class\n",
    "class RatingDataset(Dataset):\n",
    "    \"\"\"Dataset for loading user-item ratings for training\"\"\"\n",
    "    def __init__(self, user_ids, item_ids, ratings):\n",
    "        self.user_ids = torch.tensor(user_ids, dtype=torch.int64)\n",
    "        self.item_ids = torch.tensor(item_ids, dtype=torch.int64)\n",
    "        self.ratings = torch.tensor(ratings, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_ids[idx], self.item_ids[idx], self.ratings[idx]\n",
    "\n",
    "# Define the NCF model\n",
    "class NCF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, factors=20, hidden_layers=[64, 32, 16], dropout=0.2):\n",
    "        super(NCF, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, factors)\n",
    "        self.item_embedding = nn.Embedding(num_items, factors)\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        input_size = factors * 2  # Concatenate user and item embeddings\n",
    "        for hidden_layer in hidden_layers:\n",
    "            self.fc_layers.append(nn.Linear(input_size, hidden_layer))\n",
    "            input_size = hidden_layer\n",
    "        self.output = nn.Linear(input_size, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "    \n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embedding = self.user_embedding(user_indices)\n",
    "        item_embedding = self.item_embedding(item_indices)\n",
    "        x = torch.cat([user_embedding, item_embedding], dim=-1)\n",
    "        for layer in self.fc_layers:\n",
    "            x = self.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "# Training function\n",
    "def train_model(model, data_loader, criterion, optimizer, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (users, items, ratings) in enumerate(data_loader):\n",
    "            users = users.to(device)  # Move data to GPU\n",
    "            items = items.to(device)  # Move data to GPU\n",
    "            ratings = ratings.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(users, items)\n",
    "            loss = criterion(outputs, ratings)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if batch_idx % 100 == 99:\n",
    "                print(f'Epoch {epoch+1}, Batch {batch_idx+1}, Loss: {running_loss / 100:.4f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "# Prepare data\n",
    "train_data = pd.read_csv(\"cs608_ip_train_v3.csv\")\n",
    "train_data['user_id'] = train_data['user_id'].astype('category').cat.codes\n",
    "train_data['item_id'] = train_data['item_id'].astype('category').cat.codes\n",
    "dataset = RatingDataset(train_data['user_id'], train_data['item_id'], train_data['rating'])\n",
    "\n",
    "# Create DataLoader\n",
    "data_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "num_users = train_data['user_id'].nunique()\n",
    "num_items = train_data['item_id'].nunique()\n",
    "model = NCF(num_users, num_items).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, data_loader, criterion, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), \"ncf_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 1.2280008183927618\n",
      "Accuracy: 0.3194733718232342\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "# Load your CSV data\n",
    "data_path = \"./cs608_ip_probe_v3.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Assume df has columns 'user_id', 'item_id', which we need to convert to tensor\n",
    "# Also assume that 'ratings' column is your target\n",
    "users = torch.tensor(df[\"user_id\"].values).to(device)\n",
    "items = torch.tensor(df[\"item_id\"].values).to(device)\n",
    "ratings = torch.tensor(df[\"rating\"].values)\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Create a data loader for batch processing\n",
    "dataset = TensorDataset(users, items, ratings)\n",
    "data_loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# To store predictions and actual values\n",
    "predictions, actuals = [], []\n",
    "\n",
    "# Evaluate the model\n",
    "for user, item, rating in data_loader:\n",
    "    with torch.no_grad():\n",
    "        output = model(user, item)\n",
    "        predictions.extend(output.cpu().numpy())\n",
    "        actuals.extend(rating.cpu().numpy())\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "predictions = np.array(predictions)\n",
    "actuals = np.array(actuals)\n",
    "rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "accuracy = accuracy_score(actuals, predictions.round())\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def generate_recommendations(model, num_users, num_items, top_k=50):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    recommendations = []\n",
    "\n",
    "    # Iterate over all users\n",
    "    for user_id in tqdm(range(num_users)):\n",
    "        user_tensor = torch.tensor(\n",
    "            [user_id] * num_items, dtype=torch.int64\n",
    "        ).to(device)  # Repeat user ID for each item\n",
    "        item_tensor = torch.tensor(range(num_items), dtype=torch.int64).to(device)  # All item IDs\n",
    "\n",
    "        # Predict scores for all items for this user\n",
    "        with torch.no_grad():\n",
    "            scores = (\n",
    "                model(user_tensor, item_tensor).cpu().numpy()\n",
    "            )  # Get scores and move to CPU\n",
    "\n",
    "        # Get the indices of the top k scores\n",
    "        top_item_indices = scores.argsort()[-top_k:][\n",
    "            ::-1\n",
    "        ]  # Indices of top scoring items\n",
    "\n",
    "        # Append to the list of recommendations\n",
    "        recommendations.append(top_item_indices.tolist())\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd82a3fef654b19b949695990c42b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 28s, sys: 7.31 s, total: 1min 36s\n",
      "Wall time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import zipfile\n",
    "\n",
    "# Number of users and items\n",
    "num_users = train_data[\"user_id\"].nunique()\n",
    "num_items = train_data[\"item_id\"].nunique()\n",
    "\n",
    "# Generate recommendations for all users\n",
    "top_k_recommendations = generate_recommendations(model, num_users, num_items)\n",
    "\n",
    "with open(\"submission.txt\", \"w\") as file:\n",
    "    for user_recommendations in top_k_recommendations:\n",
    "        file.write(\" \".join(map(str, user_recommendations)) + \"\\n\")\n",
    "\n",
    "# zip the submission file\n",
    "with zipfile.ZipFile('submission.zip', 'w') as file:\n",
    "    file.write('submission.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
