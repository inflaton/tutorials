{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS not available because the current PyTorch install was not built with MPS enabled.\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader  \n",
    "\n",
    "# Check that MPS is available\n",
    "\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\n",
    "            \"MPS not available because the current PyTorch install was not \"\n",
    "            \"built with MPS enabled.\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "            \"and/or you do not have an MPS-enabled device on this machine.\"\n",
    "        )\n",
    "    mps_device = None\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "\n",
    "if mps_device is not None:\n",
    "    device = mps_device\n",
    "    print(\"Using MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 9.0364\n",
      "Epoch 1, Batch 200, Loss: 2.8271\n",
      "Epoch 1, Batch 300, Loss: 2.7593\n",
      "Epoch 1, Batch 400, Loss: 2.4899\n",
      "Epoch 1, Batch 500, Loss: 2.4412\n",
      "Epoch 1, Batch 600, Loss: 2.3988\n",
      "Epoch 1, Batch 700, Loss: 2.3769\n",
      "Epoch 1, Batch 800, Loss: 2.2824\n",
      "Epoch 1, Batch 900, Loss: 2.2510\n",
      "Epoch 1, Batch 1000, Loss: 2.2689\n",
      "Epoch 1, Batch 1100, Loss: 2.2172\n",
      "Epoch 1, Batch 1200, Loss: 2.1063\n",
      "Epoch 1, Batch 1300, Loss: 2.1093\n",
      "Epoch 1, Batch 1400, Loss: 2.1500\n",
      "Epoch 1, Batch 1500, Loss: 2.0329\n",
      "Epoch 1, Batch 1600, Loss: 2.0123\n",
      "Epoch 1, Batch 1700, Loss: 2.0159\n",
      "Epoch 1, Batch 1800, Loss: 2.0130\n",
      "Epoch 1, Batch 1900, Loss: 2.0140\n",
      "Epoch 1, Batch 2000, Loss: 1.9497\n",
      "Epoch 1, Batch 2100, Loss: 1.9820\n",
      "Epoch 1, Batch 2200, Loss: 1.8741\n",
      "Epoch 1, Batch 2300, Loss: 1.9650\n",
      "Epoch 1, Batch 2400, Loss: 1.9563\n",
      "Epoch 1, Batch 2500, Loss: 1.8884\n",
      "Epoch 1, Batch 2600, Loss: 1.8544\n",
      "Epoch 1, Batch 2700, Loss: 1.8447\n",
      "Epoch 1, Batch 2800, Loss: 1.8209\n",
      "Epoch 1, Batch 2900, Loss: 1.8469\n",
      "Epoch 2, Batch 100, Loss: 1.8393\n",
      "Epoch 2, Batch 200, Loss: 1.7535\n",
      "Epoch 2, Batch 300, Loss: 1.7422\n",
      "Epoch 2, Batch 400, Loss: 1.7782\n",
      "Epoch 2, Batch 500, Loss: 1.7466\n",
      "Epoch 2, Batch 600, Loss: 1.7722\n",
      "Epoch 2, Batch 700, Loss: 1.6802\n",
      "Epoch 2, Batch 800, Loss: 1.7377\n",
      "Epoch 2, Batch 900, Loss: 1.6739\n",
      "Epoch 2, Batch 1000, Loss: 1.6780\n",
      "Epoch 2, Batch 1100, Loss: 1.7232\n",
      "Epoch 2, Batch 1200, Loss: 1.6562\n",
      "Epoch 2, Batch 1300, Loss: 1.6973\n",
      "Epoch 2, Batch 1400, Loss: 1.6856\n",
      "Epoch 2, Batch 1500, Loss: 1.6429\n",
      "Epoch 2, Batch 1600, Loss: 1.6329\n",
      "Epoch 2, Batch 1700, Loss: 1.6629\n",
      "Epoch 2, Batch 1800, Loss: 1.6328\n",
      "Epoch 2, Batch 1900, Loss: 1.6431\n",
      "Epoch 2, Batch 2000, Loss: 1.5842\n",
      "Epoch 2, Batch 2100, Loss: 1.5686\n",
      "Epoch 2, Batch 2200, Loss: 1.4854\n",
      "Epoch 2, Batch 2300, Loss: 1.5159\n",
      "Epoch 2, Batch 2400, Loss: 1.5678\n",
      "Epoch 2, Batch 2500, Loss: 1.5508\n",
      "Epoch 2, Batch 2600, Loss: 1.5818\n",
      "Epoch 2, Batch 2700, Loss: 1.5042\n",
      "Epoch 2, Batch 2800, Loss: 1.5432\n",
      "Epoch 2, Batch 2900, Loss: 1.5373\n",
      "Epoch 3, Batch 100, Loss: 1.5049\n",
      "Epoch 3, Batch 200, Loss: 1.5379\n",
      "Epoch 3, Batch 300, Loss: 1.4356\n",
      "Epoch 3, Batch 400, Loss: 1.5020\n",
      "Epoch 3, Batch 500, Loss: 1.4519\n",
      "Epoch 3, Batch 600, Loss: 1.4255\n",
      "Epoch 3, Batch 700, Loss: 1.4978\n",
      "Epoch 3, Batch 800, Loss: 1.4986\n",
      "Epoch 3, Batch 900, Loss: 1.4403\n",
      "Epoch 3, Batch 1000, Loss: 1.4670\n",
      "Epoch 3, Batch 1100, Loss: 1.4885\n",
      "Epoch 3, Batch 1200, Loss: 1.4490\n",
      "Epoch 3, Batch 1300, Loss: 1.4876\n",
      "Epoch 3, Batch 1400, Loss: 1.4838\n",
      "Epoch 3, Batch 1500, Loss: 1.4313\n",
      "Epoch 3, Batch 1600, Loss: 1.4628\n",
      "Epoch 3, Batch 1700, Loss: 1.4069\n",
      "Epoch 3, Batch 1800, Loss: 1.3550\n",
      "Epoch 3, Batch 1900, Loss: 1.4310\n",
      "Epoch 3, Batch 2000, Loss: 1.4360\n",
      "Epoch 3, Batch 2100, Loss: 1.4774\n",
      "Epoch 3, Batch 2200, Loss: 1.3652\n",
      "Epoch 3, Batch 2300, Loss: 1.4310\n",
      "Epoch 3, Batch 2400, Loss: 1.3330\n",
      "Epoch 3, Batch 2500, Loss: 1.3798\n",
      "Epoch 3, Batch 2600, Loss: 1.4115\n",
      "Epoch 3, Batch 2700, Loss: 1.3724\n",
      "Epoch 3, Batch 2800, Loss: 1.3710\n",
      "Epoch 3, Batch 2900, Loss: 1.3611\n",
      "Epoch 4, Batch 100, Loss: 1.3782\n",
      "Epoch 4, Batch 200, Loss: 1.3571\n",
      "Epoch 4, Batch 300, Loss: 1.2891\n",
      "Epoch 4, Batch 400, Loss: 1.3175\n",
      "Epoch 4, Batch 500, Loss: 1.3134\n",
      "Epoch 4, Batch 600, Loss: 1.2917\n",
      "Epoch 4, Batch 700, Loss: 1.3473\n",
      "Epoch 4, Batch 800, Loss: 1.2830\n",
      "Epoch 4, Batch 900, Loss: 1.2698\n",
      "Epoch 4, Batch 1000, Loss: 1.3272\n",
      "Epoch 4, Batch 1100, Loss: 1.3236\n",
      "Epoch 4, Batch 1200, Loss: 1.2811\n",
      "Epoch 4, Batch 1300, Loss: 1.3030\n",
      "Epoch 4, Batch 1400, Loss: 1.3021\n",
      "Epoch 4, Batch 1500, Loss: 1.3141\n",
      "Epoch 4, Batch 1600, Loss: 1.3144\n",
      "Epoch 4, Batch 1700, Loss: 1.3303\n",
      "Epoch 4, Batch 1800, Loss: 1.3141\n",
      "Epoch 4, Batch 1900, Loss: 1.3264\n",
      "Epoch 4, Batch 2000, Loss: 1.2692\n",
      "Epoch 4, Batch 2100, Loss: 1.3158\n",
      "Epoch 4, Batch 2200, Loss: 1.3049\n",
      "Epoch 4, Batch 2300, Loss: 1.2869\n",
      "Epoch 4, Batch 2400, Loss: 1.3364\n",
      "Epoch 4, Batch 2500, Loss: 1.2478\n",
      "Epoch 4, Batch 2600, Loss: 1.3165\n",
      "Epoch 4, Batch 2700, Loss: 1.3084\n",
      "Epoch 4, Batch 2800, Loss: 1.3088\n",
      "Epoch 4, Batch 2900, Loss: 1.3153\n",
      "Epoch 5, Batch 100, Loss: 1.2440\n",
      "Epoch 5, Batch 200, Loss: 1.2512\n",
      "Epoch 5, Batch 300, Loss: 1.1736\n",
      "Epoch 5, Batch 400, Loss: 1.2470\n",
      "Epoch 5, Batch 500, Loss: 1.2160\n",
      "Epoch 5, Batch 600, Loss: 1.1895\n",
      "Epoch 5, Batch 700, Loss: 1.2523\n",
      "Epoch 5, Batch 800, Loss: 1.2105\n",
      "Epoch 5, Batch 900, Loss: 1.2295\n",
      "Epoch 5, Batch 1000, Loss: 1.1718\n",
      "Epoch 5, Batch 1100, Loss: 1.1942\n",
      "Epoch 5, Batch 1200, Loss: 1.2248\n",
      "Epoch 5, Batch 1300, Loss: 1.2069\n",
      "Epoch 5, Batch 1400, Loss: 1.2416\n",
      "Epoch 5, Batch 1500, Loss: 1.1548\n",
      "Epoch 5, Batch 1600, Loss: 1.1447\n",
      "Epoch 5, Batch 1700, Loss: 1.2055\n",
      "Epoch 5, Batch 1800, Loss: 1.2369\n",
      "Epoch 5, Batch 1900, Loss: 1.2276\n",
      "Epoch 5, Batch 2000, Loss: 1.2016\n",
      "Epoch 5, Batch 2100, Loss: 1.2180\n",
      "Epoch 5, Batch 2200, Loss: 1.2163\n",
      "Epoch 5, Batch 2300, Loss: 1.2464\n",
      "Epoch 5, Batch 2400, Loss: 1.2151\n",
      "Epoch 5, Batch 2500, Loss: 1.2132\n",
      "Epoch 5, Batch 2600, Loss: 1.1872\n",
      "Epoch 5, Batch 2700, Loss: 1.2157\n",
      "Epoch 5, Batch 2800, Loss: 1.1996\n",
      "Epoch 5, Batch 2900, Loss: 1.1792\n",
      "CPU times: total: 11.7 s\n",
      "Wall time: 41.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Define the dataset class\n",
    "class RatingDataset(Dataset):\n",
    "    \"\"\"Dataset for loading user-item ratings for training\"\"\"\n",
    "    def __init__(self, user_ids, item_ids, ratings):\n",
    "        self.user_ids = torch.tensor(user_ids, dtype=torch.int64)\n",
    "        self.item_ids = torch.tensor(item_ids, dtype=torch.int64)\n",
    "        self.ratings = torch.tensor(ratings, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_ids[idx], self.item_ids[idx], self.ratings[idx]\n",
    "\n",
    "# Define the NCF model\n",
    "class NCF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, factors=20, hidden_layers=[64, 32, 16], dropout=0.2):\n",
    "        super(NCF, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, factors)\n",
    "        self.item_embedding = nn.Embedding(num_items, factors)\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        input_size = factors * 2  # Concatenate user and item embeddings\n",
    "        for hidden_layer in hidden_layers:\n",
    "            self.fc_layers.append(nn.Linear(input_size, hidden_layer))\n",
    "            input_size = hidden_layer\n",
    "        self.output = nn.Linear(input_size, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "    \n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embedding = self.user_embedding(user_indices)\n",
    "        item_embedding = self.item_embedding(item_indices)\n",
    "        x = torch.cat([user_embedding, item_embedding], dim=-1)\n",
    "        for layer in self.fc_layers:\n",
    "            x = self.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "# Training function\n",
    "def train_model(model, data_loader, criterion, optimizer, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (users, items, ratings) in enumerate(data_loader):\n",
    "            users = users.to(device)  # Move data to GPU\n",
    "            items = items.to(device)  # Move data to GPU\n",
    "            ratings = ratings.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(users, items)\n",
    "            loss = criterion(outputs, ratings)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if batch_idx % 100 == 99:\n",
    "                print(f'Epoch {epoch+1}, Batch {batch_idx+1}, Loss: {running_loss / 100:.4f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "# Prepare data\n",
    "train_data = pd.read_csv(\"cs608_ip_train_v3.csv\")\n",
    "train_data['user_id'] = train_data['user_id'].astype('category').cat.codes\n",
    "train_data['item_id'] = train_data['item_id'].astype('category').cat.codes\n",
    "dataset = RatingDataset(train_data['user_id'], train_data['item_id'], train_data['rating'])\n",
    "\n",
    "# Create DataLoader\n",
    "data_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "num_users = train_data['user_id'].nunique()\n",
    "num_items = train_data['item_id'].nunique()\n",
    "model = NCF(num_users, num_items).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, data_loader, criterion, optimizer, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "torch.save(model.state_dict(), \"ncf_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     29\u001b[0m         output \u001b[38;5;241m=\u001b[39m model(user, item)\n\u001b[1;32m---> 30\u001b[0m         predictions\u001b[38;5;241m.\u001b[39mextend(\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     31\u001b[0m         actuals\u001b[38;5;241m.\u001b[39mextend(rating\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Calculate evaluation metrics\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "# Load your CSV data\n",
    "data_path = \"./cs608_ip_probe_v3.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Assume df has columns 'user_id', 'item_id', which we need to convert to tensor\n",
    "# Also assume that 'ratings' column is your target\n",
    "users = torch.tensor(df[\"user_id\"].values).to(device)\n",
    "items = torch.tensor(df[\"item_id\"].values).to(device)\n",
    "ratings = torch.tensor(df[\"rating\"].values)\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Create a data loader for batch processing\n",
    "dataset = TensorDataset(users, items, ratings)\n",
    "data_loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# To store predictions and actual values\n",
    "predictions, actuals = [], []\n",
    "\n",
    "# Evaluate the model\n",
    "for user, item, rating in data_loader:\n",
    "    with torch.no_grad():\n",
    "        output = model(user, item)\n",
    "        predictions.extend(output.cpu().numpy())\n",
    "        actuals.extend(rating.cpu().numpy())\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "predictions = np.array(predictions)\n",
    "actuals = np.array(actuals)\n",
    "rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "accuracy = accuracy_score(actuals, predictions.round())\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def generate_recommendations(model, num_users, num_items, top_k=50):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    recommendations = []\n",
    "\n",
    "    # Iterate over all users\n",
    "    for user_id in tqdm(range(num_users)):\n",
    "        user_tensor = torch.tensor(\n",
    "            [user_id] * num_items, dtype=torch.int64\n",
    "        ).to(device)  # Repeat user ID for each item\n",
    "        item_tensor = torch.tensor(range(num_items), dtype=torch.int64).to(device)  # All item IDs\n",
    "\n",
    "        # Predict scores for all items for this user\n",
    "        with torch.no_grad():\n",
    "            scores = (\n",
    "                model(user_tensor, item_tensor).cpu().numpy()\n",
    "            )  # Get scores and move to CPU\n",
    "\n",
    "        # Get the indices of the top k scores\n",
    "        top_item_indices = scores.argsort()[-top_k:][\n",
    "            ::-1\n",
    "        ]  # Indices of top scoring items\n",
    "\n",
    "        # Append to the list of recommendations\n",
    "        recommendations.append(top_item_indices.tolist())\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0eabaa6df744996a6f6b1e0b6ef74a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 59.5 s\n",
      "Wall time: 2min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import zipfile\n",
    "\n",
    "# Number of users and items\n",
    "num_users = train_data[\"user_id\"].nunique()\n",
    "num_items = train_data[\"item_id\"].nunique()\n",
    "\n",
    "# Generate recommendations for all users\n",
    "top_k_recommendations = generate_recommendations(model, num_users, num_items)\n",
    "\n",
    "with open(\"submission.txt\", \"w\") as file:\n",
    "    for user_recommendations in top_k_recommendations:\n",
    "        file.write(\" \".join(map(str, user_recommendations)) + \"\\n\")\n",
    "\n",
    "# zip the submission file\n",
    "with zipfile.ZipFile('submission.zip', 'w') as file:\n",
    "    file.write('submission.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
