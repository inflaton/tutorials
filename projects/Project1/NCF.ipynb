{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS not available because the current PyTorch install was not built with MPS enabled.\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader  \n",
    "\n",
    "# Check that MPS is available\n",
    "\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\n",
    "            \"MPS not available because the current PyTorch install was not \"\n",
    "            \"built with MPS enabled.\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "            \"and/or you do not have an MPS-enabled device on this machine.\"\n",
    "        )\n",
    "    mps_device = None\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "\n",
    "if mps_device is not None:\n",
    "    device = mps_device\n",
    "    print(\"Using MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 8.2553\n",
      "Epoch 1, Batch 200, Loss: 2.6150\n",
      "Epoch 1, Batch 300, Loss: 2.5018\n",
      "Epoch 1, Batch 400, Loss: 2.4270\n",
      "Epoch 1, Batch 500, Loss: 2.2356\n",
      "Epoch 1, Batch 600, Loss: 2.2271\n",
      "Epoch 1, Batch 700, Loss: 2.2163\n",
      "Epoch 1, Batch 800, Loss: 2.1246\n",
      "Epoch 1, Batch 900, Loss: 2.2065\n",
      "Epoch 1, Batch 1000, Loss: 2.1484\n",
      "Epoch 1, Batch 1100, Loss: 2.0330\n",
      "Epoch 1, Batch 1200, Loss: 2.0501\n",
      "Epoch 1, Batch 1300, Loss: 1.9974\n",
      "Epoch 1, Batch 1400, Loss: 1.9763\n",
      "Epoch 1, Batch 1500, Loss: 1.9518\n",
      "Epoch 1, Batch 1600, Loss: 1.9359\n",
      "Epoch 1, Batch 1700, Loss: 1.9128\n",
      "Epoch 1, Batch 1800, Loss: 1.8928\n",
      "Epoch 1, Batch 1900, Loss: 1.9243\n",
      "Epoch 1, Batch 2000, Loss: 1.9196\n",
      "Epoch 1, Batch 2100, Loss: 1.8649\n",
      "Epoch 1, Batch 2200, Loss: 1.8336\n",
      "Epoch 1, Batch 2300, Loss: 1.8559\n",
      "Epoch 1, Batch 2400, Loss: 1.8285\n",
      "Epoch 1, Batch 2500, Loss: 1.7349\n",
      "Epoch 1, Batch 2600, Loss: 1.8049\n",
      "Epoch 1, Batch 2700, Loss: 1.7671\n",
      "Epoch 1, Batch 2800, Loss: 1.8158\n",
      "Epoch 1, Batch 2900, Loss: 1.7245\n",
      "Epoch 2, Batch 100, Loss: 1.7158\n",
      "Epoch 2, Batch 200, Loss: 1.6467\n",
      "Epoch 2, Batch 300, Loss: 1.7312\n",
      "Epoch 2, Batch 400, Loss: 1.6996\n",
      "Epoch 2, Batch 500, Loss: 1.6824\n",
      "Epoch 2, Batch 600, Loss: 1.6812\n",
      "Epoch 2, Batch 700, Loss: 1.6956\n",
      "Epoch 2, Batch 800, Loss: 1.6986\n",
      "Epoch 2, Batch 900, Loss: 1.6593\n",
      "Epoch 2, Batch 1000, Loss: 1.6669\n",
      "Epoch 2, Batch 1100, Loss: 1.6462\n",
      "Epoch 2, Batch 1200, Loss: 1.5891\n",
      "Epoch 2, Batch 1300, Loss: 1.5960\n",
      "Epoch 2, Batch 1400, Loss: 1.6413\n",
      "Epoch 2, Batch 1500, Loss: 1.6726\n",
      "Epoch 2, Batch 1600, Loss: 1.6549\n",
      "Epoch 2, Batch 1700, Loss: 1.6088\n",
      "Epoch 2, Batch 1800, Loss: 1.5543\n",
      "Epoch 2, Batch 1900, Loss: 1.5454\n",
      "Epoch 2, Batch 2000, Loss: 1.5420\n",
      "Epoch 2, Batch 2100, Loss: 1.4941\n",
      "Epoch 2, Batch 2200, Loss: 1.5651\n",
      "Epoch 2, Batch 2300, Loss: 1.4948\n",
      "Epoch 2, Batch 2400, Loss: 1.5336\n",
      "Epoch 2, Batch 2500, Loss: 1.5115\n",
      "Epoch 2, Batch 2600, Loss: 1.4990\n",
      "Epoch 2, Batch 2700, Loss: 1.4646\n",
      "Epoch 2, Batch 2800, Loss: 1.5415\n",
      "Epoch 2, Batch 2900, Loss: 1.5493\n",
      "Epoch 3, Batch 100, Loss: 1.4741\n",
      "Epoch 3, Batch 200, Loss: 1.5113\n",
      "Epoch 3, Batch 300, Loss: 1.3933\n",
      "Epoch 3, Batch 400, Loss: 1.4915\n",
      "Epoch 3, Batch 500, Loss: 1.4842\n",
      "Epoch 3, Batch 600, Loss: 1.4976\n",
      "Epoch 3, Batch 700, Loss: 1.5088\n",
      "Epoch 3, Batch 800, Loss: 1.4266\n",
      "Epoch 3, Batch 900, Loss: 1.4026\n",
      "Epoch 3, Batch 1000, Loss: 1.4087\n",
      "Epoch 3, Batch 1100, Loss: 1.4573\n",
      "Epoch 3, Batch 1200, Loss: 1.4768\n",
      "Epoch 3, Batch 1300, Loss: 1.4400\n",
      "Epoch 3, Batch 1400, Loss: 1.4517\n",
      "Epoch 3, Batch 1500, Loss: 1.4187\n",
      "Epoch 3, Batch 1600, Loss: 1.4846\n",
      "Epoch 3, Batch 1700, Loss: 1.3986\n",
      "Epoch 3, Batch 1800, Loss: 1.3870\n",
      "Epoch 3, Batch 1900, Loss: 1.3858\n",
      "Epoch 3, Batch 2000, Loss: 1.3973\n",
      "Epoch 3, Batch 2100, Loss: 1.4284\n",
      "Epoch 3, Batch 2200, Loss: 1.3555\n",
      "Epoch 3, Batch 2300, Loss: 1.3815\n",
      "Epoch 3, Batch 2400, Loss: 1.4751\n",
      "Epoch 3, Batch 2500, Loss: 1.4223\n",
      "Epoch 3, Batch 2600, Loss: 1.3827\n",
      "Epoch 3, Batch 2700, Loss: 1.3705\n",
      "Epoch 3, Batch 2800, Loss: 1.3724\n",
      "Epoch 3, Batch 2900, Loss: 1.3913\n",
      "Epoch 4, Batch 100, Loss: 1.2967\n",
      "Epoch 4, Batch 200, Loss: 1.3846\n",
      "Epoch 4, Batch 300, Loss: 1.3563\n",
      "Epoch 4, Batch 400, Loss: 1.4074\n",
      "Epoch 4, Batch 500, Loss: 1.3256\n",
      "Epoch 4, Batch 600, Loss: 1.3889\n",
      "Epoch 4, Batch 700, Loss: 1.3028\n",
      "Epoch 4, Batch 800, Loss: 1.3106\n",
      "Epoch 4, Batch 900, Loss: 1.3812\n",
      "Epoch 4, Batch 1000, Loss: 1.3210\n",
      "Epoch 4, Batch 1100, Loss: 1.3501\n",
      "Epoch 4, Batch 1200, Loss: 1.3060\n",
      "Epoch 4, Batch 1300, Loss: 1.2952\n",
      "Epoch 4, Batch 1400, Loss: 1.3498\n",
      "Epoch 4, Batch 1500, Loss: 1.2962\n",
      "Epoch 4, Batch 1600, Loss: 1.3260\n",
      "Epoch 4, Batch 1700, Loss: 1.3086\n",
      "Epoch 4, Batch 1800, Loss: 1.2800\n",
      "Epoch 4, Batch 1900, Loss: 1.3208\n",
      "Epoch 4, Batch 2000, Loss: 1.2491\n",
      "Epoch 4, Batch 2100, Loss: 1.3098\n",
      "Epoch 4, Batch 2200, Loss: 1.3113\n",
      "Epoch 4, Batch 2300, Loss: 1.2688\n",
      "Epoch 4, Batch 2400, Loss: 1.3116\n",
      "Epoch 4, Batch 2500, Loss: 1.2538\n",
      "Epoch 4, Batch 2600, Loss: 1.3134\n",
      "Epoch 4, Batch 2700, Loss: 1.2562\n",
      "Epoch 4, Batch 2800, Loss: 1.3009\n",
      "Epoch 4, Batch 2900, Loss: 1.3009\n",
      "Epoch 5, Batch 100, Loss: 1.2525\n",
      "Epoch 5, Batch 200, Loss: 1.2324\n",
      "Epoch 5, Batch 300, Loss: 1.2155\n",
      "Epoch 5, Batch 400, Loss: 1.2247\n",
      "Epoch 5, Batch 500, Loss: 1.2174\n",
      "Epoch 5, Batch 600, Loss: 1.1831\n",
      "Epoch 5, Batch 700, Loss: 1.2078\n",
      "Epoch 5, Batch 800, Loss: 1.2422\n",
      "Epoch 5, Batch 900, Loss: 1.1961\n",
      "Epoch 5, Batch 1000, Loss: 1.2335\n",
      "Epoch 5, Batch 1100, Loss: 1.1669\n",
      "Epoch 5, Batch 1200, Loss: 1.1944\n",
      "Epoch 5, Batch 1300, Loss: 1.2112\n",
      "Epoch 5, Batch 1400, Loss: 1.2261\n",
      "Epoch 5, Batch 1500, Loss: 1.2316\n",
      "Epoch 5, Batch 1600, Loss: 1.2282\n",
      "Epoch 5, Batch 1700, Loss: 1.2498\n",
      "Epoch 5, Batch 1800, Loss: 1.1619\n",
      "Epoch 5, Batch 1900, Loss: 1.1740\n",
      "Epoch 5, Batch 2000, Loss: 1.2028\n",
      "Epoch 5, Batch 2100, Loss: 1.2087\n",
      "Epoch 5, Batch 2200, Loss: 1.2465\n",
      "Epoch 5, Batch 2300, Loss: 1.1849\n",
      "Epoch 5, Batch 2400, Loss: 1.1994\n",
      "Epoch 5, Batch 2500, Loss: 1.1954\n",
      "Epoch 5, Batch 2600, Loss: 1.2412\n",
      "Epoch 5, Batch 2700, Loss: 1.1742\n",
      "Epoch 5, Batch 2800, Loss: 1.2144\n",
      "Epoch 5, Batch 2900, Loss: 1.1147\n",
      "Epoch 6, Batch 100, Loss: 1.1956\n",
      "Epoch 6, Batch 200, Loss: 1.1011\n",
      "Epoch 6, Batch 300, Loss: 1.1378\n",
      "Epoch 6, Batch 400, Loss: 1.0957\n",
      "Epoch 6, Batch 500, Loss: 1.1721\n",
      "Epoch 6, Batch 600, Loss: 1.0800\n",
      "Epoch 6, Batch 700, Loss: 1.1519\n",
      "Epoch 6, Batch 800, Loss: 1.1291\n",
      "Epoch 6, Batch 900, Loss: 1.1515\n",
      "Epoch 6, Batch 1000, Loss: 1.1029\n",
      "Epoch 6, Batch 1100, Loss: 1.1583\n",
      "Epoch 6, Batch 1200, Loss: 1.1260\n",
      "Epoch 6, Batch 1300, Loss: 1.1485\n",
      "Epoch 6, Batch 1400, Loss: 1.1011\n",
      "Epoch 6, Batch 1500, Loss: 1.1063\n",
      "Epoch 6, Batch 1600, Loss: 1.1205\n",
      "Epoch 6, Batch 1700, Loss: 1.1247\n",
      "Epoch 6, Batch 1800, Loss: 1.0901\n",
      "Epoch 6, Batch 1900, Loss: 1.0928\n",
      "Epoch 6, Batch 2000, Loss: 1.0904\n",
      "Epoch 6, Batch 2100, Loss: 1.1668\n",
      "Epoch 6, Batch 2200, Loss: 1.1398\n",
      "Epoch 6, Batch 2300, Loss: 1.1345\n",
      "Epoch 6, Batch 2400, Loss: 1.0942\n",
      "Epoch 6, Batch 2500, Loss: 1.1146\n",
      "Epoch 6, Batch 2600, Loss: 1.1657\n",
      "Epoch 6, Batch 2700, Loss: 1.1128\n",
      "Epoch 6, Batch 2800, Loss: 1.0678\n",
      "Epoch 6, Batch 2900, Loss: 1.1122\n",
      "Epoch 7, Batch 100, Loss: 1.0743\n",
      "Epoch 7, Batch 200, Loss: 1.0290\n",
      "Epoch 7, Batch 300, Loss: 1.0446\n",
      "Epoch 7, Batch 400, Loss: 1.0470\n",
      "Epoch 7, Batch 500, Loss: 1.0689\n",
      "Epoch 7, Batch 600, Loss: 1.0651\n",
      "Epoch 7, Batch 700, Loss: 1.0281\n",
      "Epoch 7, Batch 800, Loss: 1.0467\n",
      "Epoch 7, Batch 900, Loss: 1.1146\n",
      "Epoch 7, Batch 1000, Loss: 1.0839\n",
      "Epoch 7, Batch 1100, Loss: 1.0545\n",
      "Epoch 7, Batch 1200, Loss: 1.0345\n",
      "Epoch 7, Batch 1300, Loss: 1.1210\n",
      "Epoch 7, Batch 1400, Loss: 1.0330\n",
      "Epoch 7, Batch 1500, Loss: 1.0592\n",
      "Epoch 7, Batch 1600, Loss: 1.0360\n",
      "Epoch 7, Batch 1700, Loss: 0.9964\n",
      "Epoch 7, Batch 1800, Loss: 1.0692\n",
      "Epoch 7, Batch 1900, Loss: 1.0679\n",
      "Epoch 7, Batch 2000, Loss: 1.0548\n",
      "Epoch 7, Batch 2100, Loss: 1.0740\n",
      "Epoch 7, Batch 2200, Loss: 1.0752\n",
      "Epoch 7, Batch 2300, Loss: 1.0624\n",
      "Epoch 7, Batch 2400, Loss: 1.0393\n",
      "Epoch 7, Batch 2500, Loss: 1.0210\n",
      "Epoch 7, Batch 2600, Loss: 1.0638\n",
      "Epoch 7, Batch 2700, Loss: 1.0416\n",
      "Epoch 7, Batch 2800, Loss: 1.0350\n",
      "Epoch 7, Batch 2900, Loss: 1.0660\n",
      "Epoch 8, Batch 100, Loss: 1.0340\n",
      "Epoch 8, Batch 200, Loss: 0.9815\n",
      "Epoch 8, Batch 300, Loss: 0.9472\n",
      "Epoch 8, Batch 400, Loss: 0.9350\n",
      "Epoch 8, Batch 500, Loss: 0.9568\n",
      "Epoch 8, Batch 600, Loss: 0.9762\n",
      "Epoch 8, Batch 700, Loss: 1.0065\n",
      "Epoch 8, Batch 800, Loss: 0.9542\n",
      "Epoch 8, Batch 900, Loss: 0.9661\n",
      "Epoch 8, Batch 1000, Loss: 1.0179\n",
      "Epoch 8, Batch 1100, Loss: 0.9565\n",
      "Epoch 8, Batch 1200, Loss: 1.0275\n",
      "Epoch 8, Batch 1300, Loss: 1.0402\n",
      "Epoch 8, Batch 1400, Loss: 1.0090\n",
      "Epoch 8, Batch 1500, Loss: 1.0146\n",
      "Epoch 8, Batch 1600, Loss: 0.9530\n",
      "Epoch 8, Batch 1700, Loss: 0.9623\n",
      "Epoch 8, Batch 1800, Loss: 0.9925\n",
      "Epoch 8, Batch 1900, Loss: 0.9826\n",
      "Epoch 8, Batch 2000, Loss: 1.0092\n",
      "Epoch 8, Batch 2100, Loss: 0.9896\n",
      "Epoch 8, Batch 2200, Loss: 0.9978\n",
      "Epoch 8, Batch 2300, Loss: 0.9606\n",
      "Epoch 8, Batch 2400, Loss: 0.9550\n",
      "Epoch 8, Batch 2500, Loss: 1.0094\n",
      "Epoch 8, Batch 2600, Loss: 1.0233\n",
      "Epoch 8, Batch 2700, Loss: 1.0048\n",
      "Epoch 8, Batch 2800, Loss: 0.9842\n",
      "Epoch 8, Batch 2900, Loss: 1.0281\n",
      "Epoch 9, Batch 100, Loss: 0.9281\n",
      "Epoch 9, Batch 200, Loss: 0.9275\n",
      "Epoch 9, Batch 300, Loss: 0.8868\n",
      "Epoch 9, Batch 400, Loss: 0.9111\n",
      "Epoch 9, Batch 500, Loss: 0.9166\n",
      "Epoch 9, Batch 600, Loss: 0.9318\n",
      "Epoch 9, Batch 700, Loss: 0.9139\n",
      "Epoch 9, Batch 800, Loss: 0.9127\n",
      "Epoch 9, Batch 900, Loss: 0.9313\n",
      "Epoch 9, Batch 1000, Loss: 0.9359\n",
      "Epoch 9, Batch 1100, Loss: 0.9456\n",
      "Epoch 9, Batch 1200, Loss: 0.9197\n",
      "Epoch 9, Batch 1300, Loss: 0.9596\n",
      "Epoch 9, Batch 1400, Loss: 0.9715\n",
      "Epoch 9, Batch 1500, Loss: 0.9820\n",
      "Epoch 9, Batch 1600, Loss: 0.9250\n",
      "Epoch 9, Batch 1700, Loss: 0.9445\n",
      "Epoch 9, Batch 1800, Loss: 0.9072\n",
      "Epoch 9, Batch 1900, Loss: 0.9241\n",
      "Epoch 9, Batch 2000, Loss: 1.0056\n",
      "Epoch 9, Batch 2100, Loss: 0.9765\n",
      "Epoch 9, Batch 2200, Loss: 0.9564\n",
      "Epoch 9, Batch 2300, Loss: 0.9121\n",
      "Epoch 9, Batch 2400, Loss: 0.9380\n",
      "Epoch 9, Batch 2500, Loss: 0.9589\n",
      "Epoch 9, Batch 2600, Loss: 0.9627\n",
      "Epoch 9, Batch 2700, Loss: 0.9419\n",
      "Epoch 9, Batch 2800, Loss: 0.9435\n",
      "Epoch 9, Batch 2900, Loss: 0.9253\n",
      "Epoch 10, Batch 100, Loss: 0.8595\n",
      "Epoch 10, Batch 200, Loss: 0.8971\n",
      "Epoch 10, Batch 300, Loss: 0.8875\n",
      "Epoch 10, Batch 400, Loss: 0.9061\n",
      "Epoch 10, Batch 500, Loss: 0.9054\n",
      "Epoch 10, Batch 600, Loss: 0.8647\n",
      "Epoch 10, Batch 700, Loss: 0.8972\n",
      "Epoch 10, Batch 800, Loss: 0.8561\n",
      "Epoch 10, Batch 900, Loss: 0.8765\n",
      "Epoch 10, Batch 1000, Loss: 0.8431\n",
      "Epoch 10, Batch 1100, Loss: 0.8657\n",
      "Epoch 10, Batch 1200, Loss: 0.8732\n",
      "Epoch 10, Batch 1300, Loss: 0.8919\n",
      "Epoch 10, Batch 1400, Loss: 0.8839\n",
      "Epoch 10, Batch 1500, Loss: 0.9233\n",
      "Epoch 10, Batch 1600, Loss: 0.9126\n",
      "Epoch 10, Batch 1700, Loss: 0.8852\n",
      "Epoch 10, Batch 1800, Loss: 0.9330\n",
      "Epoch 10, Batch 1900, Loss: 0.8532\n",
      "Epoch 10, Batch 2000, Loss: 0.8334\n",
      "Epoch 10, Batch 2100, Loss: 0.9146\n",
      "Epoch 10, Batch 2200, Loss: 0.8799\n",
      "Epoch 10, Batch 2300, Loss: 0.8798\n",
      "Epoch 10, Batch 2400, Loss: 0.8939\n",
      "Epoch 10, Batch 2500, Loss: 0.9118\n",
      "Epoch 10, Batch 2600, Loss: 0.8715\n",
      "Epoch 10, Batch 2700, Loss: 0.8984\n",
      "Epoch 10, Batch 2800, Loss: 0.8739\n",
      "Epoch 10, Batch 2900, Loss: 0.8839\n",
      "Epoch 11, Batch 100, Loss: 0.7692\n",
      "Epoch 11, Batch 200, Loss: 0.7942\n",
      "Epoch 11, Batch 300, Loss: 0.8143\n",
      "Epoch 11, Batch 400, Loss: 0.8318\n",
      "Epoch 11, Batch 500, Loss: 0.8419\n",
      "Epoch 11, Batch 600, Loss: 0.8615\n",
      "Epoch 11, Batch 700, Loss: 0.8360\n",
      "Epoch 11, Batch 800, Loss: 0.8243\n",
      "Epoch 11, Batch 900, Loss: 0.8143\n",
      "Epoch 11, Batch 1000, Loss: 0.8293\n",
      "Epoch 11, Batch 1100, Loss: 0.8471\n",
      "Epoch 11, Batch 1200, Loss: 0.8150\n",
      "Epoch 11, Batch 1300, Loss: 0.8616\n",
      "Epoch 11, Batch 1400, Loss: 0.8197\n",
      "Epoch 11, Batch 1500, Loss: 0.8541\n",
      "Epoch 11, Batch 1600, Loss: 0.8366\n",
      "Epoch 11, Batch 1700, Loss: 0.8806\n",
      "Epoch 11, Batch 1800, Loss: 0.8249\n",
      "Epoch 11, Batch 1900, Loss: 0.8085\n",
      "Epoch 11, Batch 2000, Loss: 0.8449\n",
      "Epoch 11, Batch 2100, Loss: 0.8316\n",
      "Epoch 11, Batch 2200, Loss: 0.8199\n",
      "Epoch 11, Batch 2300, Loss: 0.8949\n",
      "Epoch 11, Batch 2400, Loss: 0.8648\n",
      "Epoch 11, Batch 2500, Loss: 0.9205\n",
      "Epoch 11, Batch 2600, Loss: 0.8547\n",
      "Epoch 11, Batch 2700, Loss: 0.8638\n",
      "Epoch 11, Batch 2800, Loss: 0.8106\n",
      "Epoch 11, Batch 2900, Loss: 0.8528\n",
      "Epoch 12, Batch 100, Loss: 0.7887\n",
      "Epoch 12, Batch 200, Loss: 0.7377\n",
      "Epoch 12, Batch 300, Loss: 0.7541\n",
      "Epoch 12, Batch 400, Loss: 0.7723\n",
      "Epoch 12, Batch 500, Loss: 0.7659\n",
      "Epoch 12, Batch 600, Loss: 0.7641\n",
      "Epoch 12, Batch 700, Loss: 0.7694\n",
      "Epoch 12, Batch 800, Loss: 0.8115\n",
      "Epoch 12, Batch 900, Loss: 0.7645\n",
      "Epoch 12, Batch 1000, Loss: 0.8038\n",
      "Epoch 12, Batch 1100, Loss: 0.7901\n",
      "Epoch 12, Batch 1200, Loss: 0.7692\n",
      "Epoch 12, Batch 1300, Loss: 0.7860\n",
      "Epoch 12, Batch 1400, Loss: 0.8021\n",
      "Epoch 12, Batch 1500, Loss: 0.7967\n",
      "Epoch 12, Batch 1600, Loss: 0.7815\n",
      "Epoch 12, Batch 1700, Loss: 0.8066\n",
      "Epoch 12, Batch 1800, Loss: 0.7852\n",
      "Epoch 12, Batch 1900, Loss: 0.7947\n",
      "Epoch 12, Batch 2000, Loss: 0.8013\n",
      "Epoch 12, Batch 2100, Loss: 0.8202\n",
      "Epoch 12, Batch 2200, Loss: 0.8069\n",
      "Epoch 12, Batch 2300, Loss: 0.7971\n",
      "Epoch 12, Batch 2400, Loss: 0.8222\n",
      "Epoch 12, Batch 2500, Loss: 0.8273\n",
      "Epoch 12, Batch 2600, Loss: 0.8140\n",
      "Epoch 12, Batch 2700, Loss: 0.8248\n",
      "Epoch 12, Batch 2800, Loss: 0.8130\n",
      "Epoch 12, Batch 2900, Loss: 0.8536\n",
      "Epoch 13, Batch 100, Loss: 0.7358\n",
      "Epoch 13, Batch 200, Loss: 0.7435\n",
      "Epoch 13, Batch 300, Loss: 0.7403\n",
      "Epoch 13, Batch 400, Loss: 0.7466\n",
      "Epoch 13, Batch 500, Loss: 0.6980\n",
      "Epoch 13, Batch 600, Loss: 0.7537\n",
      "Epoch 13, Batch 700, Loss: 0.7902\n",
      "Epoch 13, Batch 800, Loss: 0.7309\n",
      "Epoch 13, Batch 900, Loss: 0.7644\n",
      "Epoch 13, Batch 1000, Loss: 0.7390\n",
      "Epoch 13, Batch 1100, Loss: 0.7549\n",
      "Epoch 13, Batch 1200, Loss: 0.7830\n",
      "Epoch 13, Batch 1300, Loss: 0.7016\n",
      "Epoch 13, Batch 1400, Loss: 0.7465\n",
      "Epoch 13, Batch 1500, Loss: 0.7257\n",
      "Epoch 13, Batch 1600, Loss: 0.7604\n",
      "Epoch 13, Batch 1700, Loss: 0.7666\n",
      "Epoch 13, Batch 1800, Loss: 0.7644\n",
      "Epoch 13, Batch 1900, Loss: 0.7416\n",
      "Epoch 13, Batch 2000, Loss: 0.8052\n",
      "Epoch 13, Batch 2100, Loss: 0.7623\n",
      "Epoch 13, Batch 2200, Loss: 0.7448\n",
      "Epoch 13, Batch 2300, Loss: 0.7597\n",
      "Epoch 13, Batch 2400, Loss: 0.7529\n",
      "Epoch 13, Batch 2500, Loss: 0.7826\n",
      "Epoch 13, Batch 2600, Loss: 0.7469\n",
      "Epoch 13, Batch 2700, Loss: 0.7452\n",
      "Epoch 13, Batch 2800, Loss: 0.7539\n",
      "Epoch 13, Batch 2900, Loss: 0.7818\n",
      "Epoch 14, Batch 100, Loss: 0.6944\n",
      "Epoch 14, Batch 200, Loss: 0.7002\n",
      "Epoch 14, Batch 300, Loss: 0.6698\n",
      "Epoch 14, Batch 400, Loss: 0.7268\n",
      "Epoch 14, Batch 500, Loss: 0.6832\n",
      "Epoch 14, Batch 600, Loss: 0.7034\n",
      "Epoch 14, Batch 700, Loss: 0.7078\n",
      "Epoch 14, Batch 800, Loss: 0.6789\n",
      "Epoch 14, Batch 900, Loss: 0.7097\n",
      "Epoch 14, Batch 1000, Loss: 0.7035\n",
      "Epoch 14, Batch 1100, Loss: 0.6958\n",
      "Epoch 14, Batch 1200, Loss: 0.6890\n",
      "Epoch 14, Batch 1300, Loss: 0.7352\n",
      "Epoch 14, Batch 1400, Loss: 0.6938\n",
      "Epoch 14, Batch 1500, Loss: 0.6980\n",
      "Epoch 14, Batch 1600, Loss: 0.7299\n",
      "Epoch 14, Batch 1700, Loss: 0.7039\n",
      "Epoch 14, Batch 1800, Loss: 0.7276\n",
      "Epoch 14, Batch 1900, Loss: 0.6924\n",
      "Epoch 14, Batch 2000, Loss: 0.7087\n",
      "Epoch 14, Batch 2100, Loss: 0.7299\n",
      "Epoch 14, Batch 2200, Loss: 0.7663\n",
      "Epoch 14, Batch 2300, Loss: 0.6854\n",
      "Epoch 14, Batch 2400, Loss: 0.7558\n",
      "Epoch 14, Batch 2500, Loss: 0.7192\n",
      "Epoch 14, Batch 2600, Loss: 0.7358\n",
      "Epoch 14, Batch 2700, Loss: 0.7696\n",
      "Epoch 14, Batch 2800, Loss: 0.7242\n",
      "Epoch 14, Batch 2900, Loss: 0.7591\n",
      "Epoch 15, Batch 100, Loss: 0.6420\n",
      "Epoch 15, Batch 200, Loss: 0.6524\n",
      "Epoch 15, Batch 300, Loss: 0.6487\n",
      "Epoch 15, Batch 400, Loss: 0.6600\n",
      "Epoch 15, Batch 500, Loss: 0.6429\n",
      "Epoch 15, Batch 600, Loss: 0.6789\n",
      "Epoch 15, Batch 700, Loss: 0.6667\n",
      "Epoch 15, Batch 800, Loss: 0.6901\n",
      "Epoch 15, Batch 900, Loss: 0.6803\n",
      "Epoch 15, Batch 1000, Loss: 0.6725\n",
      "Epoch 15, Batch 1100, Loss: 0.6526\n",
      "Epoch 15, Batch 1200, Loss: 0.6354\n",
      "Epoch 15, Batch 1300, Loss: 0.6247\n",
      "Epoch 15, Batch 1400, Loss: 0.6823\n",
      "Epoch 15, Batch 1500, Loss: 0.6983\n",
      "Epoch 15, Batch 1600, Loss: 0.6812\n",
      "Epoch 15, Batch 1700, Loss: 0.6702\n",
      "Epoch 15, Batch 1800, Loss: 0.6684\n",
      "Epoch 15, Batch 1900, Loss: 0.6553\n",
      "Epoch 15, Batch 2000, Loss: 0.7060\n",
      "Epoch 15, Batch 2100, Loss: 0.6647\n",
      "Epoch 15, Batch 2200, Loss: 0.6713\n",
      "Epoch 15, Batch 2300, Loss: 0.6787\n",
      "Epoch 15, Batch 2400, Loss: 0.6965\n",
      "Epoch 15, Batch 2500, Loss: 0.6932\n",
      "Epoch 15, Batch 2600, Loss: 0.7226\n",
      "Epoch 15, Batch 2700, Loss: 0.7133\n",
      "Epoch 15, Batch 2800, Loss: 0.7069\n",
      "Epoch 15, Batch 2900, Loss: 0.7111\n",
      "Epoch 16, Batch 100, Loss: 0.6391\n",
      "Epoch 16, Batch 200, Loss: 0.6582\n",
      "Epoch 16, Batch 300, Loss: 0.6432\n",
      "Epoch 16, Batch 400, Loss: 0.6504\n",
      "Epoch 16, Batch 500, Loss: 0.6386\n",
      "Epoch 16, Batch 600, Loss: 0.6054\n",
      "Epoch 16, Batch 700, Loss: 0.6173\n",
      "Epoch 16, Batch 800, Loss: 0.6485\n",
      "Epoch 16, Batch 900, Loss: 0.6014\n",
      "Epoch 16, Batch 1000, Loss: 0.6063\n",
      "Epoch 16, Batch 1100, Loss: 0.6553\n",
      "Epoch 16, Batch 1200, Loss: 0.6255\n",
      "Epoch 16, Batch 1300, Loss: 0.6131\n",
      "Epoch 16, Batch 1400, Loss: 0.6483\n",
      "Epoch 16, Batch 1500, Loss: 0.6489\n",
      "Epoch 16, Batch 1600, Loss: 0.6291\n",
      "Epoch 16, Batch 1700, Loss: 0.6524\n",
      "Epoch 16, Batch 1800, Loss: 0.6491\n",
      "Epoch 16, Batch 1900, Loss: 0.6424\n",
      "Epoch 16, Batch 2000, Loss: 0.6195\n",
      "Epoch 16, Batch 2100, Loss: 0.6387\n",
      "Epoch 16, Batch 2200, Loss: 0.6203\n",
      "Epoch 16, Batch 2300, Loss: 0.6227\n",
      "Epoch 16, Batch 2400, Loss: 0.6211\n",
      "Epoch 16, Batch 2500, Loss: 0.6750\n",
      "Epoch 16, Batch 2600, Loss: 0.6600\n",
      "Epoch 16, Batch 2700, Loss: 0.6637\n",
      "Epoch 16, Batch 2800, Loss: 0.6691\n",
      "Epoch 16, Batch 2900, Loss: 0.6859\n",
      "Epoch 17, Batch 100, Loss: 0.5668\n",
      "Epoch 17, Batch 200, Loss: 0.6078\n",
      "Epoch 17, Batch 300, Loss: 0.5987\n",
      "Epoch 17, Batch 400, Loss: 0.5928\n",
      "Epoch 17, Batch 500, Loss: 0.5678\n",
      "Epoch 17, Batch 600, Loss: 0.6095\n",
      "Epoch 17, Batch 700, Loss: 0.6445\n",
      "Epoch 17, Batch 800, Loss: 0.6197\n",
      "Epoch 17, Batch 900, Loss: 0.5802\n",
      "Epoch 17, Batch 1000, Loss: 0.6145\n",
      "Epoch 17, Batch 1100, Loss: 0.6147\n",
      "Epoch 17, Batch 1200, Loss: 0.5725\n",
      "Epoch 17, Batch 1300, Loss: 0.6241\n",
      "Epoch 17, Batch 1400, Loss: 0.6048\n",
      "Epoch 17, Batch 1500, Loss: 0.6216\n",
      "Epoch 17, Batch 1600, Loss: 0.5957\n",
      "Epoch 17, Batch 1700, Loss: 0.6105\n",
      "Epoch 17, Batch 1800, Loss: 0.5880\n",
      "Epoch 17, Batch 1900, Loss: 0.5952\n",
      "Epoch 17, Batch 2000, Loss: 0.6386\n",
      "Epoch 17, Batch 2100, Loss: 0.6304\n",
      "Epoch 17, Batch 2200, Loss: 0.6117\n",
      "Epoch 17, Batch 2300, Loss: 0.6208\n",
      "Epoch 17, Batch 2400, Loss: 0.6070\n",
      "Epoch 17, Batch 2500, Loss: 0.6537\n",
      "Epoch 17, Batch 2600, Loss: 0.6333\n",
      "Epoch 17, Batch 2700, Loss: 0.5985\n",
      "Epoch 17, Batch 2800, Loss: 0.6737\n",
      "Epoch 17, Batch 2900, Loss: 0.6482\n",
      "Epoch 18, Batch 100, Loss: 0.5727\n",
      "Epoch 18, Batch 200, Loss: 0.5508\n",
      "Epoch 18, Batch 300, Loss: 0.5657\n",
      "Epoch 18, Batch 400, Loss: 0.5787\n",
      "Epoch 18, Batch 500, Loss: 0.5770\n",
      "Epoch 18, Batch 600, Loss: 0.5697\n",
      "Epoch 18, Batch 700, Loss: 0.5775\n",
      "Epoch 18, Batch 800, Loss: 0.5744\n",
      "Epoch 18, Batch 900, Loss: 0.5608\n",
      "Epoch 18, Batch 1000, Loss: 0.5877\n",
      "Epoch 18, Batch 1100, Loss: 0.5616\n",
      "Epoch 18, Batch 1200, Loss: 0.6058\n",
      "Epoch 18, Batch 1300, Loss: 0.5527\n",
      "Epoch 18, Batch 1400, Loss: 0.5853\n",
      "Epoch 18, Batch 1500, Loss: 0.5828\n",
      "Epoch 18, Batch 1600, Loss: 0.5820\n",
      "Epoch 18, Batch 1700, Loss: 0.5711\n",
      "Epoch 18, Batch 1800, Loss: 0.5728\n",
      "Epoch 18, Batch 1900, Loss: 0.5760\n",
      "Epoch 18, Batch 2000, Loss: 0.5827\n",
      "Epoch 18, Batch 2100, Loss: 0.5823\n",
      "Epoch 18, Batch 2200, Loss: 0.5794\n",
      "Epoch 18, Batch 2300, Loss: 0.6225\n",
      "Epoch 18, Batch 2400, Loss: 0.6062\n",
      "Epoch 18, Batch 2500, Loss: 0.5901\n",
      "Epoch 18, Batch 2600, Loss: 0.5848\n",
      "Epoch 18, Batch 2700, Loss: 0.6000\n",
      "Epoch 18, Batch 2800, Loss: 0.5770\n",
      "Epoch 18, Batch 2900, Loss: 0.5863\n",
      "Epoch 19, Batch 100, Loss: 0.5486\n",
      "Epoch 19, Batch 200, Loss: 0.5411\n",
      "Epoch 19, Batch 300, Loss: 0.5286\n",
      "Epoch 19, Batch 400, Loss: 0.5294\n",
      "Epoch 19, Batch 500, Loss: 0.5186\n",
      "Epoch 19, Batch 600, Loss: 0.5532\n",
      "Epoch 19, Batch 700, Loss: 0.5521\n",
      "Epoch 19, Batch 800, Loss: 0.5395\n",
      "Epoch 19, Batch 900, Loss: 0.5555\n",
      "Epoch 19, Batch 1000, Loss: 0.5169\n",
      "Epoch 19, Batch 1100, Loss: 0.5303\n",
      "Epoch 19, Batch 1200, Loss: 0.5325\n",
      "Epoch 19, Batch 1300, Loss: 0.5765\n",
      "Epoch 19, Batch 1400, Loss: 0.5849\n",
      "Epoch 19, Batch 1500, Loss: 0.5728\n",
      "Epoch 19, Batch 1600, Loss: 0.5488\n",
      "Epoch 19, Batch 1700, Loss: 0.5304\n",
      "Epoch 19, Batch 1800, Loss: 0.5707\n",
      "Epoch 19, Batch 1900, Loss: 0.5599\n",
      "Epoch 19, Batch 2000, Loss: 0.5361\n",
      "Epoch 19, Batch 2100, Loss: 0.5399\n",
      "Epoch 19, Batch 2200, Loss: 0.5553\n",
      "Epoch 19, Batch 2300, Loss: 0.5717\n",
      "Epoch 19, Batch 2400, Loss: 0.5895\n",
      "Epoch 19, Batch 2500, Loss: 0.5894\n",
      "Epoch 19, Batch 2600, Loss: 0.5351\n",
      "Epoch 19, Batch 2700, Loss: 0.5848\n",
      "Epoch 19, Batch 2800, Loss: 0.5462\n",
      "Epoch 19, Batch 2900, Loss: 0.5667\n",
      "Epoch 20, Batch 100, Loss: 0.4914\n",
      "Epoch 20, Batch 200, Loss: 0.4904\n",
      "Epoch 20, Batch 300, Loss: 0.5001\n",
      "Epoch 20, Batch 400, Loss: 0.5234\n",
      "Epoch 20, Batch 500, Loss: 0.4879\n",
      "Epoch 20, Batch 600, Loss: 0.5113\n",
      "Epoch 20, Batch 700, Loss: 0.5346\n",
      "Epoch 20, Batch 800, Loss: 0.5175\n",
      "Epoch 20, Batch 900, Loss: 0.5309\n",
      "Epoch 20, Batch 1000, Loss: 0.5115\n",
      "Epoch 20, Batch 1100, Loss: 0.4964\n",
      "Epoch 20, Batch 1200, Loss: 0.5103\n",
      "Epoch 20, Batch 1300, Loss: 0.5478\n",
      "Epoch 20, Batch 1400, Loss: 0.5252\n",
      "Epoch 20, Batch 1500, Loss: 0.5644\n",
      "Epoch 20, Batch 1600, Loss: 0.5770\n",
      "Epoch 20, Batch 1700, Loss: 0.5622\n",
      "Epoch 20, Batch 1800, Loss: 0.5179\n",
      "Epoch 20, Batch 1900, Loss: 0.5471\n",
      "Epoch 20, Batch 2000, Loss: 0.5435\n",
      "Epoch 20, Batch 2100, Loss: 0.5347\n",
      "Epoch 20, Batch 2200, Loss: 0.5467\n",
      "Epoch 20, Batch 2300, Loss: 0.5655\n",
      "Epoch 20, Batch 2400, Loss: 0.5312\n",
      "Epoch 20, Batch 2500, Loss: 0.5067\n",
      "Epoch 20, Batch 2600, Loss: 0.5094\n",
      "Epoch 20, Batch 2700, Loss: 0.5142\n",
      "Epoch 20, Batch 2800, Loss: 0.5361\n",
      "Epoch 20, Batch 2900, Loss: 0.5564\n",
      "Epoch 21, Batch 100, Loss: 0.4599\n",
      "Epoch 21, Batch 200, Loss: 0.4597\n",
      "Epoch 21, Batch 300, Loss: 0.4623\n",
      "Epoch 21, Batch 400, Loss: 0.4821\n",
      "Epoch 21, Batch 500, Loss: 0.4927\n",
      "Epoch 21, Batch 600, Loss: 0.4704\n",
      "Epoch 21, Batch 700, Loss: 0.4720\n",
      "Epoch 21, Batch 800, Loss: 0.5033\n",
      "Epoch 21, Batch 900, Loss: 0.5141\n",
      "Epoch 21, Batch 1000, Loss: 0.4923\n",
      "Epoch 21, Batch 1100, Loss: 0.5223\n",
      "Epoch 21, Batch 1200, Loss: 0.5157\n",
      "Epoch 21, Batch 1300, Loss: 0.5106\n",
      "Epoch 21, Batch 1400, Loss: 0.5374\n",
      "Epoch 21, Batch 1500, Loss: 0.5027\n",
      "Epoch 21, Batch 1600, Loss: 0.4911\n",
      "Epoch 21, Batch 1700, Loss: 0.5038\n",
      "Epoch 21, Batch 1800, Loss: 0.5399\n",
      "Epoch 21, Batch 1900, Loss: 0.4961\n",
      "Epoch 21, Batch 2000, Loss: 0.4883\n",
      "Epoch 21, Batch 2100, Loss: 0.5283\n",
      "Epoch 21, Batch 2200, Loss: 0.5070\n",
      "Epoch 21, Batch 2300, Loss: 0.5005\n",
      "Epoch 21, Batch 2400, Loss: 0.5077\n",
      "Epoch 21, Batch 2500, Loss: 0.4839\n",
      "Epoch 21, Batch 2600, Loss: 0.5528\n",
      "Epoch 21, Batch 2700, Loss: 0.4928\n",
      "Epoch 21, Batch 2800, Loss: 0.5272\n",
      "Epoch 21, Batch 2900, Loss: 0.5185\n",
      "Epoch 22, Batch 100, Loss: 0.4717\n",
      "Epoch 22, Batch 200, Loss: 0.4436\n",
      "Epoch 22, Batch 300, Loss: 0.4660\n",
      "Epoch 22, Batch 400, Loss: 0.4615\n",
      "Epoch 22, Batch 500, Loss: 0.4402\n",
      "Epoch 22, Batch 600, Loss: 0.4755\n",
      "Epoch 22, Batch 700, Loss: 0.4808\n",
      "Epoch 22, Batch 800, Loss: 0.4574\n",
      "Epoch 22, Batch 900, Loss: 0.4469\n",
      "Epoch 22, Batch 1000, Loss: 0.4418\n",
      "Epoch 22, Batch 1100, Loss: 0.4571\n",
      "Epoch 22, Batch 1200, Loss: 0.4455\n",
      "Epoch 22, Batch 1300, Loss: 0.4624\n",
      "Epoch 22, Batch 1400, Loss: 0.4749\n",
      "Epoch 22, Batch 1500, Loss: 0.4585\n",
      "Epoch 22, Batch 1600, Loss: 0.5160\n",
      "Epoch 22, Batch 1700, Loss: 0.5022\n",
      "Epoch 22, Batch 1800, Loss: 0.4745\n",
      "Epoch 22, Batch 1900, Loss: 0.5042\n",
      "Epoch 22, Batch 2000, Loss: 0.4628\n",
      "Epoch 22, Batch 2100, Loss: 0.4565\n",
      "Epoch 22, Batch 2200, Loss: 0.4895\n",
      "Epoch 22, Batch 2300, Loss: 0.4913\n",
      "Epoch 22, Batch 2400, Loss: 0.5022\n",
      "Epoch 22, Batch 2500, Loss: 0.4883\n",
      "Epoch 22, Batch 2600, Loss: 0.5087\n",
      "Epoch 22, Batch 2700, Loss: 0.4846\n",
      "Epoch 22, Batch 2800, Loss: 0.5142\n",
      "Epoch 22, Batch 2900, Loss: 0.5108\n",
      "Epoch 23, Batch 100, Loss: 0.4422\n",
      "Epoch 23, Batch 200, Loss: 0.4261\n",
      "Epoch 23, Batch 300, Loss: 0.4273\n",
      "Epoch 23, Batch 400, Loss: 0.4650\n",
      "Epoch 23, Batch 500, Loss: 0.4135\n",
      "Epoch 23, Batch 600, Loss: 0.4227\n",
      "Epoch 23, Batch 700, Loss: 0.4523\n",
      "Epoch 23, Batch 800, Loss: 0.4680\n",
      "Epoch 23, Batch 900, Loss: 0.4403\n",
      "Epoch 23, Batch 1000, Loss: 0.4614\n",
      "Epoch 23, Batch 1100, Loss: 0.4500\n",
      "Epoch 23, Batch 1200, Loss: 0.4680\n",
      "Epoch 23, Batch 1300, Loss: 0.4502\n",
      "Epoch 23, Batch 1400, Loss: 0.4404\n",
      "Epoch 23, Batch 1500, Loss: 0.4511\n",
      "Epoch 23, Batch 1600, Loss: 0.4457\n",
      "Epoch 23, Batch 1700, Loss: 0.4716\n",
      "Epoch 23, Batch 1800, Loss: 0.4591\n",
      "Epoch 23, Batch 1900, Loss: 0.4413\n",
      "Epoch 23, Batch 2000, Loss: 0.4473\n",
      "Epoch 23, Batch 2100, Loss: 0.4414\n",
      "Epoch 23, Batch 2200, Loss: 0.4623\n",
      "Epoch 23, Batch 2300, Loss: 0.4469\n",
      "Epoch 23, Batch 2400, Loss: 0.4816\n",
      "Epoch 23, Batch 2500, Loss: 0.4597\n",
      "Epoch 23, Batch 2600, Loss: 0.4566\n",
      "Epoch 23, Batch 2700, Loss: 0.4743\n",
      "Epoch 23, Batch 2800, Loss: 0.5013\n",
      "Epoch 23, Batch 2900, Loss: 0.4862\n",
      "Epoch 24, Batch 100, Loss: 0.4220\n",
      "Epoch 24, Batch 200, Loss: 0.4158\n",
      "Epoch 24, Batch 300, Loss: 0.4155\n",
      "Epoch 24, Batch 400, Loss: 0.4428\n",
      "Epoch 24, Batch 500, Loss: 0.4312\n",
      "Epoch 24, Batch 600, Loss: 0.4458\n",
      "Epoch 24, Batch 700, Loss: 0.4466\n",
      "Epoch 24, Batch 800, Loss: 0.4237\n",
      "Epoch 24, Batch 900, Loss: 0.4136\n",
      "Epoch 24, Batch 1000, Loss: 0.4162\n",
      "Epoch 24, Batch 1100, Loss: 0.4730\n",
      "Epoch 24, Batch 1200, Loss: 0.4215\n",
      "Epoch 24, Batch 1300, Loss: 0.4137\n",
      "Epoch 24, Batch 1400, Loss: 0.4369\n",
      "Epoch 24, Batch 1500, Loss: 0.4201\n",
      "Epoch 24, Batch 1600, Loss: 0.4347\n",
      "Epoch 24, Batch 1700, Loss: 0.4483\n",
      "Epoch 24, Batch 1800, Loss: 0.4137\n",
      "Epoch 24, Batch 1900, Loss: 0.4551\n",
      "Epoch 24, Batch 2000, Loss: 0.4288\n",
      "Epoch 24, Batch 2100, Loss: 0.4403\n",
      "Epoch 24, Batch 2200, Loss: 0.4443\n",
      "Epoch 24, Batch 2300, Loss: 0.4497\n",
      "Epoch 24, Batch 2400, Loss: 0.4517\n",
      "Epoch 24, Batch 2500, Loss: 0.4443\n",
      "Epoch 24, Batch 2600, Loss: 0.4520\n",
      "Epoch 24, Batch 2700, Loss: 0.4330\n",
      "Epoch 24, Batch 2800, Loss: 0.4538\n",
      "Epoch 24, Batch 2900, Loss: 0.4497\n",
      "Epoch 25, Batch 100, Loss: 0.4154\n",
      "Epoch 25, Batch 200, Loss: 0.4023\n",
      "Epoch 25, Batch 300, Loss: 0.3872\n",
      "Epoch 25, Batch 400, Loss: 0.4021\n",
      "Epoch 25, Batch 500, Loss: 0.4074\n",
      "Epoch 25, Batch 600, Loss: 0.4302\n",
      "Epoch 25, Batch 700, Loss: 0.4370\n",
      "Epoch 25, Batch 800, Loss: 0.4069\n",
      "Epoch 25, Batch 900, Loss: 0.4104\n",
      "Epoch 25, Batch 1000, Loss: 0.3938\n",
      "Epoch 25, Batch 1100, Loss: 0.4352\n",
      "Epoch 25, Batch 1200, Loss: 0.3966\n",
      "Epoch 25, Batch 1300, Loss: 0.3983\n",
      "Epoch 25, Batch 1400, Loss: 0.4398\n",
      "Epoch 25, Batch 1500, Loss: 0.4193\n",
      "Epoch 25, Batch 1600, Loss: 0.4235\n",
      "Epoch 25, Batch 1700, Loss: 0.4067\n",
      "Epoch 25, Batch 1800, Loss: 0.3972\n",
      "Epoch 25, Batch 1900, Loss: 0.4073\n",
      "Epoch 25, Batch 2000, Loss: 0.4298\n",
      "Epoch 25, Batch 2100, Loss: 0.3996\n",
      "Epoch 25, Batch 2200, Loss: 0.4351\n",
      "Epoch 25, Batch 2300, Loss: 0.4099\n",
      "Epoch 25, Batch 2400, Loss: 0.4189\n",
      "Epoch 25, Batch 2500, Loss: 0.4116\n",
      "Epoch 25, Batch 2600, Loss: 0.4204\n",
      "Epoch 25, Batch 2700, Loss: 0.4141\n",
      "Epoch 25, Batch 2800, Loss: 0.4334\n",
      "Epoch 25, Batch 2900, Loss: 0.4182\n",
      "Epoch 26, Batch 100, Loss: 0.3991\n",
      "Epoch 26, Batch 200, Loss: 0.3952\n",
      "Epoch 26, Batch 300, Loss: 0.3912\n",
      "Epoch 26, Batch 400, Loss: 0.3978\n",
      "Epoch 26, Batch 500, Loss: 0.3674\n",
      "Epoch 26, Batch 600, Loss: 0.3991\n",
      "Epoch 26, Batch 700, Loss: 0.3893\n",
      "Epoch 26, Batch 800, Loss: 0.4046\n",
      "Epoch 26, Batch 900, Loss: 0.4022\n",
      "Epoch 26, Batch 1000, Loss: 0.4037\n",
      "Epoch 26, Batch 1100, Loss: 0.3985\n",
      "Epoch 26, Batch 1200, Loss: 0.4036\n",
      "Epoch 26, Batch 1300, Loss: 0.3877\n",
      "Epoch 26, Batch 1400, Loss: 0.3739\n",
      "Epoch 26, Batch 1500, Loss: 0.4079\n",
      "Epoch 26, Batch 1600, Loss: 0.4076\n",
      "Epoch 26, Batch 1700, Loss: 0.4055\n",
      "Epoch 26, Batch 1800, Loss: 0.3970\n",
      "Epoch 26, Batch 1900, Loss: 0.3721\n",
      "Epoch 26, Batch 2000, Loss: 0.4020\n",
      "Epoch 26, Batch 2100, Loss: 0.4406\n",
      "Epoch 26, Batch 2200, Loss: 0.4069\n",
      "Epoch 26, Batch 2300, Loss: 0.4271\n",
      "Epoch 26, Batch 2400, Loss: 0.3979\n",
      "Epoch 26, Batch 2500, Loss: 0.4057\n",
      "Epoch 26, Batch 2600, Loss: 0.4108\n",
      "Epoch 26, Batch 2700, Loss: 0.4107\n",
      "Epoch 26, Batch 2800, Loss: 0.4315\n",
      "Epoch 26, Batch 2900, Loss: 0.4050\n",
      "Epoch 27, Batch 100, Loss: 0.3685\n",
      "Epoch 27, Batch 200, Loss: 0.3955\n",
      "Epoch 27, Batch 300, Loss: 0.3793\n",
      "Epoch 27, Batch 400, Loss: 0.3810\n",
      "Epoch 27, Batch 500, Loss: 0.4264\n",
      "Epoch 27, Batch 600, Loss: 0.3568\n",
      "Epoch 27, Batch 700, Loss: 0.3735\n",
      "Epoch 27, Batch 800, Loss: 0.3821\n",
      "Epoch 27, Batch 900, Loss: 0.3536\n",
      "Epoch 27, Batch 1000, Loss: 0.3734\n",
      "Epoch 27, Batch 1100, Loss: 0.3684\n",
      "Epoch 27, Batch 1200, Loss: 0.3859\n",
      "Epoch 27, Batch 1300, Loss: 0.3834\n",
      "Epoch 27, Batch 1400, Loss: 0.3791\n",
      "Epoch 27, Batch 1500, Loss: 0.3849\n",
      "Epoch 27, Batch 1600, Loss: 0.3807\n",
      "Epoch 27, Batch 1700, Loss: 0.4067\n",
      "Epoch 27, Batch 1800, Loss: 0.3696\n",
      "Epoch 27, Batch 1900, Loss: 0.3681\n",
      "Epoch 27, Batch 2000, Loss: 0.3969\n",
      "Epoch 27, Batch 2100, Loss: 0.4101\n",
      "Epoch 27, Batch 2200, Loss: 0.3918\n",
      "Epoch 27, Batch 2300, Loss: 0.3816\n",
      "Epoch 27, Batch 2400, Loss: 0.3820\n",
      "Epoch 27, Batch 2500, Loss: 0.4076\n",
      "Epoch 27, Batch 2600, Loss: 0.3875\n",
      "Epoch 27, Batch 2700, Loss: 0.4016\n",
      "Epoch 27, Batch 2800, Loss: 0.3856\n",
      "Epoch 27, Batch 2900, Loss: 0.3750\n",
      "Epoch 28, Batch 100, Loss: 0.3674\n",
      "Epoch 28, Batch 200, Loss: 0.3599\n",
      "Epoch 28, Batch 300, Loss: 0.3757\n",
      "Epoch 28, Batch 400, Loss: 0.3832\n",
      "Epoch 28, Batch 500, Loss: 0.3531\n",
      "Epoch 28, Batch 600, Loss: 0.3597\n",
      "Epoch 28, Batch 700, Loss: 0.3635\n",
      "Epoch 28, Batch 800, Loss: 0.4075\n",
      "Epoch 28, Batch 900, Loss: 0.3649\n",
      "Epoch 28, Batch 1000, Loss: 0.3655\n",
      "Epoch 28, Batch 1100, Loss: 0.3566\n",
      "Epoch 28, Batch 1200, Loss: 0.3601\n",
      "Epoch 28, Batch 1300, Loss: 0.3774\n",
      "Epoch 28, Batch 1400, Loss: 0.3852\n",
      "Epoch 28, Batch 1500, Loss: 0.3459\n",
      "Epoch 28, Batch 1600, Loss: 0.3724\n",
      "Epoch 28, Batch 1700, Loss: 0.3709\n",
      "Epoch 28, Batch 1800, Loss: 0.3641\n",
      "Epoch 28, Batch 1900, Loss: 0.3571\n",
      "Epoch 28, Batch 2000, Loss: 0.3785\n",
      "Epoch 28, Batch 2100, Loss: 0.3731\n",
      "Epoch 28, Batch 2200, Loss: 0.3797\n",
      "Epoch 28, Batch 2300, Loss: 0.3979\n",
      "Epoch 28, Batch 2400, Loss: 0.3809\n",
      "Epoch 28, Batch 2500, Loss: 0.3855\n",
      "Epoch 28, Batch 2600, Loss: 0.3626\n",
      "Epoch 28, Batch 2700, Loss: 0.3864\n",
      "Epoch 28, Batch 2800, Loss: 0.3545\n",
      "Epoch 28, Batch 2900, Loss: 0.3908\n",
      "Epoch 29, Batch 100, Loss: 0.3528\n",
      "Epoch 29, Batch 200, Loss: 0.3386\n",
      "Epoch 29, Batch 300, Loss: 0.3606\n",
      "Epoch 29, Batch 400, Loss: 0.3500\n",
      "Epoch 29, Batch 500, Loss: 0.3420\n",
      "Epoch 29, Batch 600, Loss: 0.3228\n",
      "Epoch 29, Batch 700, Loss: 0.3579\n",
      "Epoch 29, Batch 800, Loss: 0.3512\n",
      "Epoch 29, Batch 900, Loss: 0.3350\n",
      "Epoch 29, Batch 1000, Loss: 0.3469\n",
      "Epoch 29, Batch 1100, Loss: 0.3649\n",
      "Epoch 29, Batch 1200, Loss: 0.3438\n",
      "Epoch 29, Batch 1300, Loss: 0.3488\n",
      "Epoch 29, Batch 1400, Loss: 0.3549\n",
      "Epoch 29, Batch 1500, Loss: 0.3205\n",
      "Epoch 29, Batch 1600, Loss: 0.3656\n",
      "Epoch 29, Batch 1700, Loss: 0.3719\n",
      "Epoch 29, Batch 1800, Loss: 0.3673\n",
      "Epoch 29, Batch 1900, Loss: 0.3601\n",
      "Epoch 29, Batch 2000, Loss: 0.3895\n",
      "Epoch 29, Batch 2100, Loss: 0.3745\n",
      "Epoch 29, Batch 2200, Loss: 0.3847\n",
      "Epoch 29, Batch 2300, Loss: 0.3996\n",
      "Epoch 29, Batch 2400, Loss: 0.3961\n",
      "Epoch 29, Batch 2500, Loss: 0.3485\n",
      "Epoch 29, Batch 2600, Loss: 0.3612\n",
      "Epoch 29, Batch 2700, Loss: 0.3585\n",
      "Epoch 29, Batch 2800, Loss: 0.3581\n",
      "Epoch 29, Batch 2900, Loss: 0.3615\n",
      "Epoch 30, Batch 100, Loss: 0.3205\n",
      "Epoch 30, Batch 200, Loss: 0.3452\n",
      "Epoch 30, Batch 300, Loss: 0.3405\n",
      "Epoch 30, Batch 400, Loss: 0.3291\n",
      "Epoch 30, Batch 500, Loss: 0.3129\n",
      "Epoch 30, Batch 600, Loss: 0.3294\n",
      "Epoch 30, Batch 700, Loss: 0.3492\n",
      "Epoch 30, Batch 800, Loss: 0.3570\n",
      "Epoch 30, Batch 900, Loss: 0.3379\n",
      "Epoch 30, Batch 1000, Loss: 0.3378\n",
      "Epoch 30, Batch 1100, Loss: 0.3286\n",
      "Epoch 30, Batch 1200, Loss: 0.3832\n",
      "Epoch 30, Batch 1300, Loss: 0.3500\n",
      "Epoch 30, Batch 1400, Loss: 0.3527\n",
      "Epoch 30, Batch 1500, Loss: 0.3438\n",
      "Epoch 30, Batch 1600, Loss: 0.3367\n",
      "Epoch 30, Batch 1700, Loss: 0.3375\n",
      "Epoch 30, Batch 1800, Loss: 0.3817\n",
      "Epoch 30, Batch 1900, Loss: 0.3685\n",
      "Epoch 30, Batch 2000, Loss: 0.3682\n",
      "Epoch 30, Batch 2100, Loss: 0.3430\n",
      "Epoch 30, Batch 2200, Loss: 0.3638\n",
      "Epoch 30, Batch 2300, Loss: 0.3434\n",
      "Epoch 30, Batch 2400, Loss: 0.3597\n",
      "Epoch 30, Batch 2500, Loss: 0.3381\n",
      "Epoch 30, Batch 2600, Loss: 0.3723\n",
      "Epoch 30, Batch 2700, Loss: 0.3497\n",
      "Epoch 30, Batch 2800, Loss: 0.3735\n",
      "Epoch 30, Batch 2900, Loss: 0.3409\n",
      "Epoch 31, Batch 100, Loss: 0.3081\n",
      "Epoch 31, Batch 200, Loss: 0.3544\n",
      "Epoch 31, Batch 300, Loss: 0.3074\n",
      "Epoch 31, Batch 400, Loss: 0.3312\n",
      "Epoch 31, Batch 500, Loss: 0.3216\n",
      "Epoch 31, Batch 600, Loss: 0.3570\n",
      "Epoch 31, Batch 700, Loss: 0.3233\n",
      "Epoch 31, Batch 800, Loss: 0.3208\n",
      "Epoch 31, Batch 900, Loss: 0.3199\n",
      "Epoch 31, Batch 1000, Loss: 0.3387\n",
      "Epoch 31, Batch 1100, Loss: 0.3458\n",
      "Epoch 31, Batch 1200, Loss: 0.3350\n",
      "Epoch 31, Batch 1300, Loss: 0.3338\n",
      "Epoch 31, Batch 1400, Loss: 0.3260\n",
      "Epoch 31, Batch 1500, Loss: 0.3439\n",
      "Epoch 31, Batch 1600, Loss: 0.3325\n",
      "Epoch 31, Batch 1700, Loss: 0.3600\n",
      "Epoch 31, Batch 1800, Loss: 0.3394\n",
      "Epoch 31, Batch 1900, Loss: 0.3412\n",
      "Epoch 31, Batch 2000, Loss: 0.3277\n",
      "Epoch 31, Batch 2100, Loss: 0.3458\n",
      "Epoch 31, Batch 2200, Loss: 0.3344\n",
      "Epoch 31, Batch 2300, Loss: 0.3400\n",
      "Epoch 31, Batch 2400, Loss: 0.3395\n",
      "Epoch 31, Batch 2500, Loss: 0.3432\n",
      "Epoch 31, Batch 2600, Loss: 0.3286\n",
      "Epoch 31, Batch 2700, Loss: 0.3634\n",
      "Epoch 31, Batch 2800, Loss: 0.3425\n",
      "Epoch 31, Batch 2900, Loss: 0.3430\n",
      "Epoch 32, Batch 100, Loss: 0.3147\n",
      "Epoch 32, Batch 200, Loss: 0.3152\n",
      "Epoch 32, Batch 300, Loss: 0.2908\n",
      "Epoch 32, Batch 400, Loss: 0.2984\n",
      "Epoch 32, Batch 500, Loss: 0.3486\n",
      "Epoch 32, Batch 600, Loss: 0.3243\n",
      "Epoch 32, Batch 700, Loss: 0.3148\n",
      "Epoch 32, Batch 800, Loss: 0.3092\n",
      "Epoch 32, Batch 900, Loss: 0.3164\n",
      "Epoch 32, Batch 1000, Loss: 0.3152\n",
      "Epoch 32, Batch 1100, Loss: 0.3507\n",
      "Epoch 32, Batch 1200, Loss: 0.3486\n",
      "Epoch 32, Batch 1300, Loss: 0.3048\n",
      "Epoch 32, Batch 1400, Loss: 0.3396\n",
      "Epoch 32, Batch 1500, Loss: 0.3136\n",
      "Epoch 32, Batch 1600, Loss: 0.3365\n",
      "Epoch 32, Batch 1700, Loss: 0.3377\n",
      "Epoch 32, Batch 1800, Loss: 0.3323\n",
      "Epoch 32, Batch 1900, Loss: 0.3049\n",
      "Epoch 32, Batch 2000, Loss: 0.3016\n",
      "Epoch 32, Batch 2100, Loss: 0.3393\n",
      "Epoch 32, Batch 2200, Loss: 0.3131\n",
      "Epoch 32, Batch 2300, Loss: 0.3314\n",
      "Epoch 32, Batch 2400, Loss: 0.3417\n",
      "Epoch 32, Batch 2500, Loss: 0.3289\n",
      "Epoch 32, Batch 2600, Loss: 0.3252\n",
      "Epoch 32, Batch 2700, Loss: 0.3343\n",
      "Epoch 32, Batch 2800, Loss: 0.3383\n",
      "Epoch 32, Batch 2900, Loss: 0.3604\n",
      "Epoch 33, Batch 100, Loss: 0.3108\n",
      "Epoch 33, Batch 200, Loss: 0.3148\n",
      "Epoch 33, Batch 300, Loss: 0.3096\n",
      "Epoch 33, Batch 400, Loss: 0.3121\n",
      "Epoch 33, Batch 500, Loss: 0.3052\n",
      "Epoch 33, Batch 600, Loss: 0.3232\n",
      "Epoch 33, Batch 700, Loss: 0.3124\n",
      "Epoch 33, Batch 800, Loss: 0.3290\n",
      "Epoch 33, Batch 900, Loss: 0.3051\n",
      "Epoch 33, Batch 1000, Loss: 0.3081\n",
      "Epoch 33, Batch 1100, Loss: 0.3189\n",
      "Epoch 33, Batch 1200, Loss: 0.3025\n",
      "Epoch 33, Batch 1300, Loss: 0.3048\n",
      "Epoch 33, Batch 1400, Loss: 0.3370\n",
      "Epoch 33, Batch 1500, Loss: 0.3109\n",
      "Epoch 33, Batch 1600, Loss: 0.3448\n",
      "Epoch 33, Batch 1700, Loss: 0.3074\n",
      "Epoch 33, Batch 1800, Loss: 0.3143\n",
      "Epoch 33, Batch 1900, Loss: 0.3416\n",
      "Epoch 33, Batch 2000, Loss: 0.3050\n",
      "Epoch 33, Batch 2100, Loss: 0.2977\n",
      "Epoch 33, Batch 2200, Loss: 0.3362\n",
      "Epoch 33, Batch 2300, Loss: 0.3167\n",
      "Epoch 33, Batch 2400, Loss: 0.3312\n",
      "Epoch 33, Batch 2500, Loss: 0.3289\n",
      "Epoch 33, Batch 2600, Loss: 0.2972\n",
      "Epoch 33, Batch 2700, Loss: 0.3072\n",
      "Epoch 33, Batch 2800, Loss: 0.3519\n",
      "Epoch 33, Batch 2900, Loss: 0.3009\n",
      "Epoch 34, Batch 100, Loss: 0.2779\n",
      "Epoch 34, Batch 200, Loss: 0.2940\n",
      "Epoch 34, Batch 300, Loss: 0.3004\n",
      "Epoch 34, Batch 400, Loss: 0.3046\n",
      "Epoch 34, Batch 500, Loss: 0.2862\n",
      "Epoch 34, Batch 600, Loss: 0.3129\n",
      "Epoch 34, Batch 700, Loss: 0.3013\n",
      "Epoch 34, Batch 800, Loss: 0.3354\n",
      "Epoch 34, Batch 900, Loss: 0.2895\n",
      "Epoch 34, Batch 1000, Loss: 0.2985\n",
      "Epoch 34, Batch 1100, Loss: 0.2973\n",
      "Epoch 34, Batch 1200, Loss: 0.3101\n",
      "Epoch 34, Batch 1300, Loss: 0.3302\n",
      "Epoch 34, Batch 1400, Loss: 0.3064\n",
      "Epoch 34, Batch 1500, Loss: 0.2841\n",
      "Epoch 34, Batch 1600, Loss: 0.2988\n",
      "Epoch 34, Batch 1700, Loss: 0.2890\n",
      "Epoch 34, Batch 1800, Loss: 0.3056\n",
      "Epoch 34, Batch 1900, Loss: 0.3248\n",
      "Epoch 34, Batch 2000, Loss: 0.3269\n",
      "Epoch 34, Batch 2100, Loss: 0.2984\n",
      "Epoch 34, Batch 2200, Loss: 0.3183\n",
      "Epoch 34, Batch 2300, Loss: 0.3103\n",
      "Epoch 34, Batch 2400, Loss: 0.3199\n",
      "Epoch 34, Batch 2500, Loss: 0.3122\n",
      "Epoch 34, Batch 2600, Loss: 0.3199\n",
      "Epoch 34, Batch 2700, Loss: 0.3173\n",
      "Epoch 34, Batch 2800, Loss: 0.3229\n",
      "Epoch 34, Batch 2900, Loss: 0.3011\n",
      "Epoch 35, Batch 100, Loss: 0.3040\n",
      "Epoch 35, Batch 200, Loss: 0.2815\n",
      "Epoch 35, Batch 300, Loss: 0.2915\n",
      "Epoch 35, Batch 400, Loss: 0.2743\n",
      "Epoch 35, Batch 500, Loss: 0.2747\n",
      "Epoch 35, Batch 600, Loss: 0.2792\n",
      "Epoch 35, Batch 700, Loss: 0.3010\n",
      "Epoch 35, Batch 800, Loss: 0.3023\n",
      "Epoch 35, Batch 900, Loss: 0.2860\n",
      "Epoch 35, Batch 1000, Loss: 0.2988\n",
      "Epoch 35, Batch 1100, Loss: 0.2647\n",
      "Epoch 35, Batch 1200, Loss: 0.2822\n",
      "Epoch 35, Batch 1300, Loss: 0.3006\n",
      "Epoch 35, Batch 1400, Loss: 0.2838\n",
      "Epoch 35, Batch 1500, Loss: 0.3001\n",
      "Epoch 35, Batch 1600, Loss: 0.2829\n",
      "Epoch 35, Batch 1700, Loss: 0.3196\n",
      "Epoch 35, Batch 1800, Loss: 0.3023\n",
      "Epoch 35, Batch 1900, Loss: 0.3052\n",
      "Epoch 35, Batch 2000, Loss: 0.3009\n",
      "Epoch 35, Batch 2100, Loss: 0.3135\n",
      "Epoch 35, Batch 2200, Loss: 0.3107\n",
      "Epoch 35, Batch 2300, Loss: 0.2848\n",
      "Epoch 35, Batch 2400, Loss: 0.3062\n",
      "Epoch 35, Batch 2500, Loss: 0.3076\n",
      "Epoch 35, Batch 2600, Loss: 0.3138\n",
      "Epoch 35, Batch 2700, Loss: 0.3170\n",
      "Epoch 35, Batch 2800, Loss: 0.2990\n",
      "Epoch 35, Batch 2900, Loss: 0.3154\n",
      "Epoch 36, Batch 100, Loss: 0.2787\n",
      "Epoch 36, Batch 200, Loss: 0.2639\n",
      "Epoch 36, Batch 300, Loss: 0.2836\n",
      "Epoch 36, Batch 400, Loss: 0.2905\n",
      "Epoch 36, Batch 500, Loss: 0.2715\n",
      "Epoch 36, Batch 600, Loss: 0.2846\n",
      "Epoch 36, Batch 700, Loss: 0.3045\n",
      "Epoch 36, Batch 800, Loss: 0.2693\n",
      "Epoch 36, Batch 900, Loss: 0.2958\n",
      "Epoch 36, Batch 1000, Loss: 0.2842\n",
      "Epoch 36, Batch 1100, Loss: 0.2839\n",
      "Epoch 36, Batch 1200, Loss: 0.2962\n",
      "Epoch 36, Batch 1300, Loss: 0.2814\n",
      "Epoch 36, Batch 1400, Loss: 0.2917\n",
      "Epoch 36, Batch 1500, Loss: 0.2788\n",
      "Epoch 36, Batch 1600, Loss: 0.2836\n",
      "Epoch 36, Batch 1700, Loss: 0.2857\n",
      "Epoch 36, Batch 1800, Loss: 0.2892\n",
      "Epoch 36, Batch 1900, Loss: 0.2836\n",
      "Epoch 36, Batch 2000, Loss: 0.2939\n",
      "Epoch 36, Batch 2100, Loss: 0.2888\n",
      "Epoch 36, Batch 2200, Loss: 0.3094\n",
      "Epoch 36, Batch 2300, Loss: 0.3078\n",
      "Epoch 36, Batch 2400, Loss: 0.3052\n",
      "Epoch 36, Batch 2500, Loss: 0.3031\n",
      "Epoch 36, Batch 2600, Loss: 0.3076\n",
      "Epoch 36, Batch 2700, Loss: 0.3271\n",
      "Epoch 36, Batch 2800, Loss: 0.2999\n",
      "Epoch 36, Batch 2900, Loss: 0.2973\n",
      "Epoch 37, Batch 100, Loss: 0.2950\n",
      "Epoch 37, Batch 200, Loss: 0.2688\n",
      "Epoch 37, Batch 300, Loss: 0.2690\n",
      "Epoch 37, Batch 400, Loss: 0.2668\n",
      "Epoch 37, Batch 500, Loss: 0.2941\n",
      "Epoch 37, Batch 600, Loss: 0.2675\n",
      "Epoch 37, Batch 700, Loss: 0.2701\n",
      "Epoch 37, Batch 800, Loss: 0.2737\n",
      "Epoch 37, Batch 900, Loss: 0.2958\n",
      "Epoch 37, Batch 1000, Loss: 0.2767\n",
      "Epoch 37, Batch 1100, Loss: 0.2760\n",
      "Epoch 37, Batch 1200, Loss: 0.2939\n",
      "Epoch 37, Batch 1300, Loss: 0.2828\n",
      "Epoch 37, Batch 1400, Loss: 0.2983\n",
      "Epoch 37, Batch 1500, Loss: 0.2696\n",
      "Epoch 37, Batch 1600, Loss: 0.2799\n",
      "Epoch 37, Batch 1700, Loss: 0.2725\n",
      "Epoch 37, Batch 1800, Loss: 0.2916\n",
      "Epoch 37, Batch 1900, Loss: 0.2723\n",
      "Epoch 37, Batch 2000, Loss: 0.3044\n",
      "Epoch 37, Batch 2100, Loss: 0.2792\n",
      "Epoch 37, Batch 2200, Loss: 0.2654\n",
      "Epoch 37, Batch 2300, Loss: 0.2945\n",
      "Epoch 37, Batch 2400, Loss: 0.3038\n",
      "Epoch 37, Batch 2500, Loss: 0.3002\n",
      "Epoch 37, Batch 2600, Loss: 0.2859\n",
      "Epoch 37, Batch 2700, Loss: 0.2903\n",
      "Epoch 37, Batch 2800, Loss: 0.2992\n",
      "Epoch 37, Batch 2900, Loss: 0.2800\n",
      "Epoch 38, Batch 100, Loss: 0.2594\n",
      "Epoch 38, Batch 200, Loss: 0.2739\n",
      "Epoch 38, Batch 300, Loss: 0.2611\n",
      "Epoch 38, Batch 400, Loss: 0.2680\n",
      "Epoch 38, Batch 500, Loss: 0.2502\n",
      "Epoch 38, Batch 600, Loss: 0.2673\n",
      "Epoch 38, Batch 700, Loss: 0.2710\n",
      "Epoch 38, Batch 800, Loss: 0.2799\n",
      "Epoch 38, Batch 900, Loss: 0.2552\n",
      "Epoch 38, Batch 1000, Loss: 0.2790\n",
      "Epoch 38, Batch 1100, Loss: 0.2663\n",
      "Epoch 38, Batch 1200, Loss: 0.2682\n",
      "Epoch 38, Batch 1300, Loss: 0.2640\n",
      "Epoch 38, Batch 1400, Loss: 0.2755\n",
      "Epoch 38, Batch 1500, Loss: 0.2812\n",
      "Epoch 38, Batch 1600, Loss: 0.2910\n",
      "Epoch 38, Batch 1700, Loss: 0.2665\n",
      "Epoch 38, Batch 1800, Loss: 0.2828\n",
      "Epoch 38, Batch 1900, Loss: 0.2854\n",
      "Epoch 38, Batch 2000, Loss: 0.3008\n",
      "Epoch 38, Batch 2100, Loss: 0.2902\n",
      "Epoch 38, Batch 2200, Loss: 0.2867\n",
      "Epoch 38, Batch 2300, Loss: 0.2753\n",
      "Epoch 38, Batch 2400, Loss: 0.2856\n",
      "Epoch 38, Batch 2500, Loss: 0.2615\n",
      "Epoch 38, Batch 2600, Loss: 0.2890\n",
      "Epoch 38, Batch 2700, Loss: 0.2977\n",
      "Epoch 38, Batch 2800, Loss: 0.2867\n",
      "Epoch 38, Batch 2900, Loss: 0.3085\n",
      "Epoch 39, Batch 100, Loss: 0.2497\n",
      "Epoch 39, Batch 200, Loss: 0.2758\n",
      "Epoch 39, Batch 300, Loss: 0.2544\n",
      "Epoch 39, Batch 400, Loss: 0.2708\n",
      "Epoch 39, Batch 500, Loss: 0.2611\n",
      "Epoch 39, Batch 600, Loss: 0.2529\n",
      "Epoch 39, Batch 700, Loss: 0.2683\n",
      "Epoch 39, Batch 800, Loss: 0.2864\n",
      "Epoch 39, Batch 900, Loss: 0.2629\n",
      "Epoch 39, Batch 1000, Loss: 0.2632\n",
      "Epoch 39, Batch 1100, Loss: 0.2750\n",
      "Epoch 39, Batch 1200, Loss: 0.2670\n",
      "Epoch 39, Batch 1300, Loss: 0.2656\n",
      "Epoch 39, Batch 1400, Loss: 0.2511\n",
      "Epoch 39, Batch 1500, Loss: 0.2786\n",
      "Epoch 39, Batch 1600, Loss: 0.2500\n",
      "Epoch 39, Batch 1700, Loss: 0.2689\n",
      "Epoch 39, Batch 1800, Loss: 0.2719\n",
      "Epoch 39, Batch 1900, Loss: 0.2642\n",
      "Epoch 39, Batch 2000, Loss: 0.2783\n",
      "Epoch 39, Batch 2100, Loss: 0.2761\n",
      "Epoch 39, Batch 2200, Loss: 0.2819\n",
      "Epoch 39, Batch 2300, Loss: 0.3077\n",
      "Epoch 39, Batch 2400, Loss: 0.2621\n",
      "Epoch 39, Batch 2500, Loss: 0.2774\n",
      "Epoch 39, Batch 2600, Loss: 0.2871\n",
      "Epoch 39, Batch 2700, Loss: 0.2592\n",
      "Epoch 39, Batch 2800, Loss: 0.2815\n",
      "Epoch 39, Batch 2900, Loss: 0.2671\n",
      "Epoch 40, Batch 100, Loss: 0.2635\n",
      "Epoch 40, Batch 200, Loss: 0.2585\n",
      "Epoch 40, Batch 300, Loss: 0.2702\n",
      "Epoch 40, Batch 400, Loss: 0.2598\n",
      "Epoch 40, Batch 500, Loss: 0.2587\n",
      "Epoch 40, Batch 600, Loss: 0.2395\n",
      "Epoch 40, Batch 700, Loss: 0.2806\n",
      "Epoch 40, Batch 800, Loss: 0.2715\n",
      "Epoch 40, Batch 900, Loss: 0.2596\n",
      "Epoch 40, Batch 1000, Loss: 0.2732\n",
      "Epoch 40, Batch 1100, Loss: 0.2541\n",
      "Epoch 40, Batch 1200, Loss: 0.2707\n",
      "Epoch 40, Batch 1300, Loss: 0.2561\n",
      "Epoch 40, Batch 1400, Loss: 0.2703\n",
      "Epoch 40, Batch 1500, Loss: 0.2756\n",
      "Epoch 40, Batch 1600, Loss: 0.2508\n",
      "Epoch 40, Batch 1700, Loss: 0.2510\n",
      "Epoch 40, Batch 1800, Loss: 0.2750\n",
      "Epoch 40, Batch 1900, Loss: 0.2708\n",
      "Epoch 40, Batch 2000, Loss: 0.2653\n",
      "Epoch 40, Batch 2100, Loss: 0.2755\n",
      "Epoch 40, Batch 2200, Loss: 0.2729\n",
      "Epoch 40, Batch 2300, Loss: 0.2660\n",
      "Epoch 40, Batch 2400, Loss: 0.2733\n",
      "Epoch 40, Batch 2500, Loss: 0.2705\n",
      "Epoch 40, Batch 2600, Loss: 0.2716\n",
      "Epoch 40, Batch 2700, Loss: 0.2625\n",
      "Epoch 40, Batch 2800, Loss: 0.2546\n",
      "Epoch 40, Batch 2900, Loss: 0.2658\n",
      "Epoch 41, Batch 100, Loss: 0.2549\n",
      "Epoch 41, Batch 200, Loss: 0.2482\n",
      "Epoch 41, Batch 300, Loss: 0.2460\n",
      "Epoch 41, Batch 400, Loss: 0.2561\n",
      "Epoch 41, Batch 500, Loss: 0.2586\n",
      "Epoch 41, Batch 600, Loss: 0.2556\n",
      "Epoch 41, Batch 700, Loss: 0.2566\n",
      "Epoch 41, Batch 800, Loss: 0.2492\n",
      "Epoch 41, Batch 900, Loss: 0.2635\n",
      "Epoch 41, Batch 1000, Loss: 0.2458\n",
      "Epoch 41, Batch 1100, Loss: 0.2671\n",
      "Epoch 41, Batch 1200, Loss: 0.2322\n",
      "Epoch 41, Batch 1300, Loss: 0.2628\n",
      "Epoch 41, Batch 1400, Loss: 0.2538\n",
      "Epoch 41, Batch 1500, Loss: 0.2498\n",
      "Epoch 41, Batch 1600, Loss: 0.2775\n",
      "Epoch 41, Batch 1700, Loss: 0.2487\n",
      "Epoch 41, Batch 1800, Loss: 0.2601\n",
      "Epoch 41, Batch 1900, Loss: 0.2616\n",
      "Epoch 41, Batch 2000, Loss: 0.2450\n",
      "Epoch 41, Batch 2100, Loss: 0.2738\n",
      "Epoch 41, Batch 2200, Loss: 0.2537\n",
      "Epoch 41, Batch 2300, Loss: 0.2675\n",
      "Epoch 41, Batch 2400, Loss: 0.2552\n",
      "Epoch 41, Batch 2500, Loss: 0.2520\n",
      "Epoch 41, Batch 2600, Loss: 0.2920\n",
      "Epoch 41, Batch 2700, Loss: 0.2579\n",
      "Epoch 41, Batch 2800, Loss: 0.2827\n",
      "Epoch 41, Batch 2900, Loss: 0.2706\n",
      "Epoch 42, Batch 100, Loss: 0.2489\n",
      "Epoch 42, Batch 200, Loss: 0.2447\n",
      "Epoch 42, Batch 300, Loss: 0.2387\n",
      "Epoch 42, Batch 400, Loss: 0.2377\n",
      "Epoch 42, Batch 500, Loss: 0.2495\n",
      "Epoch 42, Batch 600, Loss: 0.2441\n",
      "Epoch 42, Batch 700, Loss: 0.2603\n",
      "Epoch 42, Batch 800, Loss: 0.2518\n",
      "Epoch 42, Batch 900, Loss: 0.2615\n",
      "Epoch 42, Batch 1000, Loss: 0.2523\n",
      "Epoch 42, Batch 1100, Loss: 0.2571\n",
      "Epoch 42, Batch 1200, Loss: 0.2514\n",
      "Epoch 42, Batch 1300, Loss: 0.2495\n",
      "Epoch 42, Batch 1400, Loss: 0.2440\n",
      "Epoch 42, Batch 1500, Loss: 0.2600\n",
      "Epoch 42, Batch 1600, Loss: 0.2443\n",
      "Epoch 42, Batch 1700, Loss: 0.2558\n",
      "Epoch 42, Batch 1800, Loss: 0.2568\n",
      "Epoch 42, Batch 1900, Loss: 0.2487\n",
      "Epoch 42, Batch 2000, Loss: 0.2642\n",
      "Epoch 42, Batch 2100, Loss: 0.2529\n",
      "Epoch 42, Batch 2200, Loss: 0.2538\n",
      "Epoch 42, Batch 2300, Loss: 0.2493\n",
      "Epoch 42, Batch 2400, Loss: 0.2507\n",
      "Epoch 42, Batch 2500, Loss: 0.2461\n",
      "Epoch 42, Batch 2600, Loss: 0.2487\n",
      "Epoch 42, Batch 2700, Loss: 0.2607\n",
      "Epoch 42, Batch 2800, Loss: 0.2647\n",
      "Epoch 42, Batch 2900, Loss: 0.2760\n",
      "Epoch 43, Batch 100, Loss: 0.2344\n",
      "Epoch 43, Batch 200, Loss: 0.2363\n",
      "Epoch 43, Batch 300, Loss: 0.2424\n",
      "Epoch 43, Batch 400, Loss: 0.2452\n",
      "Epoch 43, Batch 500, Loss: 0.2512\n",
      "Epoch 43, Batch 600, Loss: 0.2258\n",
      "Epoch 43, Batch 700, Loss: 0.2430\n",
      "Epoch 43, Batch 800, Loss: 0.2591\n",
      "Epoch 43, Batch 900, Loss: 0.2547\n",
      "Epoch 43, Batch 1000, Loss: 0.2322\n",
      "Epoch 43, Batch 1100, Loss: 0.2462\n",
      "Epoch 43, Batch 1200, Loss: 0.2154\n",
      "Epoch 43, Batch 1300, Loss: 0.2451\n",
      "Epoch 43, Batch 1400, Loss: 0.2431\n",
      "Epoch 43, Batch 1500, Loss: 0.2253\n",
      "Epoch 43, Batch 1600, Loss: 0.2532\n",
      "Epoch 43, Batch 1700, Loss: 0.2387\n",
      "Epoch 43, Batch 1800, Loss: 0.2634\n",
      "Epoch 43, Batch 1900, Loss: 0.2550\n",
      "Epoch 43, Batch 2000, Loss: 0.2681\n",
      "Epoch 43, Batch 2100, Loss: 0.2392\n",
      "Epoch 43, Batch 2200, Loss: 0.2574\n",
      "Epoch 43, Batch 2300, Loss: 0.2556\n",
      "Epoch 43, Batch 2400, Loss: 0.2485\n",
      "Epoch 43, Batch 2500, Loss: 0.2381\n",
      "Epoch 43, Batch 2600, Loss: 0.2625\n",
      "Epoch 43, Batch 2700, Loss: 0.2513\n",
      "Epoch 43, Batch 2800, Loss: 0.2501\n",
      "Epoch 43, Batch 2900, Loss: 0.2617\n",
      "Epoch 44, Batch 100, Loss: 0.2410\n",
      "Epoch 44, Batch 200, Loss: 0.2166\n",
      "Epoch 44, Batch 300, Loss: 0.2519\n",
      "Epoch 44, Batch 400, Loss: 0.2348\n",
      "Epoch 44, Batch 500, Loss: 0.2431\n",
      "Epoch 44, Batch 600, Loss: 0.2191\n",
      "Epoch 44, Batch 700, Loss: 0.2286\n",
      "Epoch 44, Batch 800, Loss: 0.2217\n",
      "Epoch 44, Batch 900, Loss: 0.2412\n",
      "Epoch 44, Batch 1000, Loss: 0.2416\n",
      "Epoch 44, Batch 1100, Loss: 0.2442\n",
      "Epoch 44, Batch 1200, Loss: 0.2629\n",
      "Epoch 44, Batch 1300, Loss: 0.2311\n",
      "Epoch 44, Batch 1400, Loss: 0.2686\n",
      "Epoch 44, Batch 1500, Loss: 0.2206\n",
      "Epoch 44, Batch 1600, Loss: 0.2594\n",
      "Epoch 44, Batch 1700, Loss: 0.2522\n",
      "Epoch 44, Batch 1800, Loss: 0.2505\n",
      "Epoch 44, Batch 1900, Loss: 0.2447\n",
      "Epoch 44, Batch 2000, Loss: 0.2595\n",
      "Epoch 44, Batch 2100, Loss: 0.2494\n",
      "Epoch 44, Batch 2200, Loss: 0.2509\n",
      "Epoch 44, Batch 2300, Loss: 0.2651\n",
      "Epoch 44, Batch 2400, Loss: 0.2473\n",
      "Epoch 44, Batch 2500, Loss: 0.2340\n",
      "Epoch 44, Batch 2600, Loss: 0.2438\n",
      "Epoch 44, Batch 2700, Loss: 0.2482\n",
      "Epoch 44, Batch 2800, Loss: 0.2565\n",
      "Epoch 44, Batch 2900, Loss: 0.2403\n",
      "Epoch 45, Batch 100, Loss: 0.2431\n",
      "Epoch 45, Batch 200, Loss: 0.2230\n",
      "Epoch 45, Batch 300, Loss: 0.2405\n",
      "Epoch 45, Batch 400, Loss: 0.2107\n",
      "Epoch 45, Batch 500, Loss: 0.2280\n",
      "Epoch 45, Batch 600, Loss: 0.2356\n",
      "Epoch 45, Batch 700, Loss: 0.2441\n",
      "Epoch 45, Batch 800, Loss: 0.2281\n",
      "Epoch 45, Batch 900, Loss: 0.2204\n",
      "Epoch 45, Batch 1000, Loss: 0.2509\n",
      "Epoch 45, Batch 1100, Loss: 0.2211\n",
      "Epoch 45, Batch 1200, Loss: 0.2432\n",
      "Epoch 45, Batch 1300, Loss: 0.2358\n",
      "Epoch 45, Batch 1400, Loss: 0.2445\n",
      "Epoch 45, Batch 1500, Loss: 0.2361\n",
      "Epoch 45, Batch 1600, Loss: 0.2415\n",
      "Epoch 45, Batch 1700, Loss: 0.2336\n",
      "Epoch 45, Batch 1800, Loss: 0.2402\n",
      "Epoch 45, Batch 1900, Loss: 0.2501\n",
      "Epoch 45, Batch 2000, Loss: 0.2394\n",
      "Epoch 45, Batch 2100, Loss: 0.2474\n",
      "Epoch 45, Batch 2200, Loss: 0.2477\n",
      "Epoch 45, Batch 2300, Loss: 0.2566\n",
      "Epoch 45, Batch 2400, Loss: 0.2532\n",
      "Epoch 45, Batch 2500, Loss: 0.2592\n",
      "Epoch 45, Batch 2600, Loss: 0.2364\n",
      "Epoch 45, Batch 2700, Loss: 0.2518\n",
      "Epoch 45, Batch 2800, Loss: 0.2294\n",
      "Epoch 45, Batch 2900, Loss: 0.2522\n",
      "Epoch 46, Batch 100, Loss: 0.2226\n",
      "Epoch 46, Batch 200, Loss: 0.2358\n",
      "Epoch 46, Batch 300, Loss: 0.2232\n",
      "Epoch 46, Batch 400, Loss: 0.2333\n",
      "Epoch 46, Batch 500, Loss: 0.2281\n",
      "Epoch 46, Batch 600, Loss: 0.2180\n",
      "Epoch 46, Batch 700, Loss: 0.2466\n",
      "Epoch 46, Batch 800, Loss: 0.2376\n",
      "Epoch 46, Batch 900, Loss: 0.2356\n",
      "Epoch 46, Batch 1000, Loss: 0.2345\n",
      "Epoch 46, Batch 1100, Loss: 0.2165\n",
      "Epoch 46, Batch 1200, Loss: 0.2390\n",
      "Epoch 46, Batch 1300, Loss: 0.2294\n",
      "Epoch 46, Batch 1400, Loss: 0.2325\n",
      "Epoch 46, Batch 1500, Loss: 0.2235\n",
      "Epoch 46, Batch 1600, Loss: 0.2413\n",
      "Epoch 46, Batch 1700, Loss: 0.2278\n",
      "Epoch 46, Batch 1800, Loss: 0.2139\n",
      "Epoch 46, Batch 1900, Loss: 0.2357\n",
      "Epoch 46, Batch 2000, Loss: 0.2431\n",
      "Epoch 46, Batch 2100, Loss: 0.2352\n",
      "Epoch 46, Batch 2200, Loss: 0.2387\n",
      "Epoch 46, Batch 2300, Loss: 0.2434\n",
      "Epoch 46, Batch 2400, Loss: 0.2367\n",
      "Epoch 46, Batch 2500, Loss: 0.2227\n",
      "Epoch 46, Batch 2600, Loss: 0.2281\n",
      "Epoch 46, Batch 2700, Loss: 0.2224\n",
      "Epoch 46, Batch 2800, Loss: 0.2571\n",
      "Epoch 46, Batch 2900, Loss: 0.2414\n",
      "Epoch 47, Batch 100, Loss: 0.2320\n",
      "Epoch 47, Batch 200, Loss: 0.2225\n",
      "Epoch 47, Batch 300, Loss: 0.2307\n",
      "Epoch 47, Batch 400, Loss: 0.2125\n",
      "Epoch 47, Batch 500, Loss: 0.2361\n",
      "Epoch 47, Batch 600, Loss: 0.2245\n",
      "Epoch 47, Batch 700, Loss: 0.2254\n",
      "Epoch 47, Batch 800, Loss: 0.2249\n",
      "Epoch 47, Batch 900, Loss: 0.2155\n",
      "Epoch 47, Batch 1000, Loss: 0.2401\n",
      "Epoch 47, Batch 1100, Loss: 0.2255\n",
      "Epoch 47, Batch 1200, Loss: 0.2184\n",
      "Epoch 47, Batch 1300, Loss: 0.2073\n",
      "Epoch 47, Batch 1400, Loss: 0.2184\n",
      "Epoch 47, Batch 1500, Loss: 0.2284\n",
      "Epoch 47, Batch 1600, Loss: 0.2375\n",
      "Epoch 47, Batch 1700, Loss: 0.2222\n",
      "Epoch 47, Batch 1800, Loss: 0.2084\n",
      "Epoch 47, Batch 1900, Loss: 0.2340\n",
      "Epoch 47, Batch 2000, Loss: 0.2328\n",
      "Epoch 47, Batch 2100, Loss: 0.2377\n",
      "Epoch 47, Batch 2200, Loss: 0.2409\n",
      "Epoch 47, Batch 2300, Loss: 0.2311\n",
      "Epoch 47, Batch 2400, Loss: 0.2399\n",
      "Epoch 47, Batch 2500, Loss: 0.2393\n",
      "Epoch 47, Batch 2600, Loss: 0.2492\n",
      "Epoch 47, Batch 2700, Loss: 0.2415\n",
      "Epoch 47, Batch 2800, Loss: 0.2343\n",
      "Epoch 47, Batch 2900, Loss: 0.2419\n",
      "Epoch 48, Batch 100, Loss: 0.2247\n",
      "Epoch 48, Batch 200, Loss: 0.2214\n",
      "Epoch 48, Batch 300, Loss: 0.2100\n",
      "Epoch 48, Batch 400, Loss: 0.1999\n",
      "Epoch 48, Batch 500, Loss: 0.2060\n",
      "Epoch 48, Batch 600, Loss: 0.2285\n",
      "Epoch 48, Batch 700, Loss: 0.2078\n",
      "Epoch 48, Batch 800, Loss: 0.2307\n",
      "Epoch 48, Batch 900, Loss: 0.2277\n",
      "Epoch 48, Batch 1000, Loss: 0.2444\n",
      "Epoch 48, Batch 1100, Loss: 0.2318\n",
      "Epoch 48, Batch 1200, Loss: 0.2210\n",
      "Epoch 48, Batch 1300, Loss: 0.2326\n",
      "Epoch 48, Batch 1400, Loss: 0.2247\n",
      "Epoch 48, Batch 1500, Loss: 0.2223\n",
      "Epoch 48, Batch 1600, Loss: 0.2211\n",
      "Epoch 48, Batch 1700, Loss: 0.2271\n",
      "Epoch 48, Batch 1800, Loss: 0.2247\n",
      "Epoch 48, Batch 1900, Loss: 0.2125\n",
      "Epoch 48, Batch 2000, Loss: 0.2206\n",
      "Epoch 48, Batch 2100, Loss: 0.2503\n",
      "Epoch 48, Batch 2200, Loss: 0.2323\n",
      "Epoch 48, Batch 2300, Loss: 0.2369\n",
      "Epoch 48, Batch 2400, Loss: 0.2073\n",
      "Epoch 48, Batch 2500, Loss: 0.2404\n",
      "Epoch 48, Batch 2600, Loss: 0.2331\n",
      "Epoch 48, Batch 2700, Loss: 0.2334\n",
      "Epoch 48, Batch 2800, Loss: 0.2240\n",
      "Epoch 48, Batch 2900, Loss: 0.2474\n",
      "Epoch 49, Batch 100, Loss: 0.2137\n",
      "Epoch 49, Batch 200, Loss: 0.2067\n",
      "Epoch 49, Batch 300, Loss: 0.2198\n",
      "Epoch 49, Batch 400, Loss: 0.2028\n",
      "Epoch 49, Batch 500, Loss: 0.2113\n",
      "Epoch 49, Batch 600, Loss: 0.2115\n",
      "Epoch 49, Batch 700, Loss: 0.2109\n",
      "Epoch 49, Batch 800, Loss: 0.2117\n",
      "Epoch 49, Batch 900, Loss: 0.2112\n",
      "Epoch 49, Batch 1000, Loss: 0.2148\n",
      "Epoch 49, Batch 1100, Loss: 0.2283\n",
      "Epoch 49, Batch 1200, Loss: 0.2258\n",
      "Epoch 49, Batch 1300, Loss: 0.2411\n",
      "Epoch 49, Batch 1400, Loss: 0.2251\n",
      "Epoch 49, Batch 1500, Loss: 0.2278\n",
      "Epoch 49, Batch 1600, Loss: 0.2264\n",
      "Epoch 49, Batch 1700, Loss: 0.2219\n",
      "Epoch 49, Batch 1800, Loss: 0.2375\n",
      "Epoch 49, Batch 1900, Loss: 0.2143\n",
      "Epoch 49, Batch 2000, Loss: 0.2227\n",
      "Epoch 49, Batch 2100, Loss: 0.2249\n",
      "Epoch 49, Batch 2200, Loss: 0.2276\n",
      "Epoch 49, Batch 2300, Loss: 0.2179\n",
      "Epoch 49, Batch 2400, Loss: 0.2226\n",
      "Epoch 49, Batch 2500, Loss: 0.2146\n",
      "Epoch 49, Batch 2600, Loss: 0.2184\n",
      "Epoch 49, Batch 2700, Loss: 0.2058\n",
      "Epoch 49, Batch 2800, Loss: 0.2263\n",
      "Epoch 49, Batch 2900, Loss: 0.2312\n",
      "Epoch 50, Batch 100, Loss: 0.2016\n",
      "Epoch 50, Batch 200, Loss: 0.2196\n",
      "Epoch 50, Batch 300, Loss: 0.1937\n",
      "Epoch 50, Batch 400, Loss: 0.2086\n",
      "Epoch 50, Batch 500, Loss: 0.2075\n",
      "Epoch 50, Batch 600, Loss: 0.2065\n",
      "Epoch 50, Batch 700, Loss: 0.2121\n",
      "Epoch 50, Batch 800, Loss: 0.2230\n",
      "Epoch 50, Batch 900, Loss: 0.2177\n",
      "Epoch 50, Batch 1000, Loss: 0.1964\n",
      "Epoch 50, Batch 1100, Loss: 0.2242\n",
      "Epoch 50, Batch 1200, Loss: 0.2083\n",
      "Epoch 50, Batch 1300, Loss: 0.2162\n",
      "Epoch 50, Batch 1400, Loss: 0.1947\n",
      "Epoch 50, Batch 1500, Loss: 0.2027\n",
      "Epoch 50, Batch 1600, Loss: 0.2149\n",
      "Epoch 50, Batch 1700, Loss: 0.2182\n",
      "Epoch 50, Batch 1800, Loss: 0.2087\n",
      "Epoch 50, Batch 1900, Loss: 0.2133\n",
      "Epoch 50, Batch 2000, Loss: 0.2088\n",
      "Epoch 50, Batch 2100, Loss: 0.2190\n",
      "Epoch 50, Batch 2200, Loss: 0.2212\n",
      "Epoch 50, Batch 2300, Loss: 0.2280\n",
      "Epoch 50, Batch 2400, Loss: 0.2336\n",
      "Epoch 50, Batch 2500, Loss: 0.2128\n",
      "Epoch 50, Batch 2600, Loss: 0.2078\n",
      "Epoch 50, Batch 2700, Loss: 0.2091\n",
      "Epoch 50, Batch 2800, Loss: 0.2268\n",
      "Epoch 50, Batch 2900, Loss: 0.2218\n",
      "CPU times: total: 1min 40s\n",
      "Wall time: 6min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Define the dataset class\n",
    "class RatingDataset(Dataset):\n",
    "    \"\"\"Dataset for loading user-item ratings for training\"\"\"\n",
    "    def __init__(self, user_ids, item_ids, ratings):\n",
    "        self.user_ids = torch.tensor(user_ids, dtype=torch.int64)\n",
    "        self.item_ids = torch.tensor(item_ids, dtype=torch.int64)\n",
    "        self.ratings = torch.tensor(ratings, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_ids[idx], self.item_ids[idx], self.ratings[idx]\n",
    "\n",
    "# Define the NCF model\n",
    "class NCF(nn.Module):\n",
    "    def __init__(self, num_users, num_items, factors=20, hidden_layers=[64, 32, 16], dropout=0.2):\n",
    "        super(NCF, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, factors)\n",
    "        self.item_embedding = nn.Embedding(num_items, factors)\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        input_size = factors * 2  # Concatenate user and item embeddings\n",
    "        for hidden_layer in hidden_layers:\n",
    "            self.fc_layers.append(nn.Linear(input_size, hidden_layer))\n",
    "            input_size = hidden_layer\n",
    "        self.output = nn.Linear(input_size, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "    \n",
    "    def forward(self, user_indices, item_indices):\n",
    "        user_embedding = self.user_embedding(user_indices)\n",
    "        item_embedding = self.item_embedding(item_indices)\n",
    "        x = torch.cat([user_embedding, item_embedding], dim=-1)\n",
    "        for layer in self.fc_layers:\n",
    "            x = self.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "        x = self.output(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "# Training function\n",
    "def train_model(model, data_loader, criterion, optimizer, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (users, items, ratings) in enumerate(data_loader):\n",
    "            users = users.to(device)  # Move data to GPU\n",
    "            items = items.to(device)  # Move data to GPU\n",
    "            ratings = ratings.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(users, items)\n",
    "            loss = criterion(outputs, ratings)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if batch_idx % 100 == 99:\n",
    "                print(f'Epoch {epoch+1}, Batch {batch_idx+1}, Loss: {running_loss / 100:.4f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "# Prepare data\n",
    "train_data = pd.read_csv(\"cs608_ip_train_v3.csv\")\n",
    "train_data['user_id'] = train_data['user_id'].astype('category').cat.codes\n",
    "train_data['item_id'] = train_data['item_id'].astype('category').cat.codes\n",
    "dataset = RatingDataset(train_data['user_id'], train_data['item_id'], train_data['rating'])\n",
    "\n",
    "# Create DataLoader\n",
    "data_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "num_users = train_data['user_id'].nunique()\n",
    "num_items = train_data['item_id'].nunique()\n",
    "model = NCF(num_users, num_items).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, data_loader, criterion, optimizer, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def generate_recommendations(model, num_users, num_items, top_k=50):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    recommendations = []\n",
    "\n",
    "    # Iterate over all users\n",
    "    for user_id in tqdm(range(num_users)):\n",
    "        user_tensor = torch.tensor(\n",
    "            [user_id] * num_items, dtype=torch.int64\n",
    "        ).to(device)  # Repeat user ID for each item\n",
    "        item_tensor = torch.tensor(range(num_items), dtype=torch.int64).to(device)  # All item IDs\n",
    "\n",
    "        # Predict scores for all items for this user\n",
    "        with torch.no_grad():\n",
    "            scores = (\n",
    "                model(user_tensor, item_tensor).cpu().numpy()\n",
    "            )  # Get scores and move to CPU\n",
    "\n",
    "        # Get the indices of the top k scores\n",
    "        top_item_indices = scores.argsort()[-top_k:][\n",
    "            ::-1\n",
    "        ]  # Indices of top scoring items\n",
    "\n",
    "        # Append to the list of recommendations\n",
    "        recommendations.append(top_item_indices.tolist())\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1024f2444ad14d66bafe9aa185508338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1min 16s\n",
      "Wall time: 2min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import zipfile\n",
    "\n",
    "# Number of users and items\n",
    "num_users = train_data[\"user_id\"].nunique()\n",
    "num_items = train_data[\"item_id\"].nunique()\n",
    "\n",
    "# Generate recommendations for all users\n",
    "top_k_recommendations = generate_recommendations(model, num_users, num_items)\n",
    "\n",
    "with open(\"submission.txt\", \"w\") as file:\n",
    "    for user_recommendations in top_k_recommendations:\n",
    "        file.write(\" \".join(map(str, user_recommendations)) + \"\\n\")\n",
    "\n",
    "# zip the submission file\n",
    "with zipfile.ZipFile('submission.zip', 'w') as file:\n",
    "    file.write('submission.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
