{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS not available because the current PyTorch install was not built with MPS enabled.\n",
      "Using GPU: NVIDIA GeForce RTX 4080 Laptop GPU\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader  \n",
    "\n",
    "# Check that MPS is available\n",
    "\n",
    "if not torch.backends.mps.is_available():\n",
    "    if not torch.backends.mps.is_built():\n",
    "        print(\n",
    "            \"MPS not available because the current PyTorch install was not \"\n",
    "            \"built with MPS enabled.\"\n",
    "        )\n",
    "    else:\n",
    "        print(\n",
    "            \"MPS not available because the current MacOS version is not 12.3+ \"\n",
    "            \"and/or you do not have an MPS-enabled device on this machine.\"\n",
    "        )\n",
    "    mps_device = None\n",
    "else:\n",
    "    mps_device = torch.device(\"mps\")\n",
    "\n",
    "if mps_device is not None:\n",
    "    device = mps_device\n",
    "    print(\"Using MPS\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using GPU: {torch.cuda.get_device_name(device)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"Using CPU\")\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 100, Loss: 8.9168\n",
      "Epoch 1, Batch 200, Loss: 3.5820\n",
      "Epoch 1, Batch 300, Loss: 3.5746\n",
      "Epoch 1, Batch 400, Loss: 3.3771\n",
      "Epoch 1, Batch 500, Loss: 3.3333\n",
      "Epoch 1, Batch 600, Loss: 3.3555\n",
      "Epoch 1, Batch 700, Loss: 3.2803\n",
      "Epoch 1, Batch 800, Loss: 3.1857\n",
      "Epoch 1, Batch 900, Loss: 3.1720\n",
      "Epoch 1, Batch 1000, Loss: 3.0940\n",
      "Epoch 1, Batch 1100, Loss: 3.0077\n",
      "Epoch 1, Batch 1200, Loss: 3.0645\n",
      "Epoch 1, Batch 1300, Loss: 3.0632\n",
      "Epoch 1, Batch 1400, Loss: 2.9743\n",
      "Epoch 1, Batch 1500, Loss: 2.7887\n",
      "Epoch 1, Batch 1600, Loss: 2.9168\n",
      "Epoch 1, Batch 1700, Loss: 2.8890\n",
      "Epoch 1, Batch 1800, Loss: 2.8450\n",
      "Epoch 1, Batch 1900, Loss: 2.9801\n",
      "Epoch 1, Batch 2000, Loss: 2.6914\n",
      "Epoch 1, Batch 2100, Loss: 2.7990\n",
      "Epoch 1, Batch 2200, Loss: 2.7569\n",
      "Epoch 1, Batch 2300, Loss: 2.7950\n",
      "Epoch 1, Batch 2400, Loss: 2.7273\n",
      "Epoch 1, Batch 2500, Loss: 2.6596\n",
      "Epoch 1, Batch 2600, Loss: 2.6867\n",
      "Epoch 1, Batch 2700, Loss: 2.7836\n",
      "Epoch 1, Batch 2800, Loss: 2.7150\n",
      "Epoch 1, Batch 2900, Loss: 2.6132\n",
      "Epoch 2, Batch 100, Loss: 2.6231\n",
      "Epoch 2, Batch 200, Loss: 2.6618\n",
      "Epoch 2, Batch 300, Loss: 2.5878\n",
      "Epoch 2, Batch 400, Loss: 2.6378\n",
      "Epoch 2, Batch 500, Loss: 2.6175\n",
      "Epoch 2, Batch 600, Loss: 2.6102\n",
      "Epoch 2, Batch 700, Loss: 2.6111\n",
      "Epoch 2, Batch 800, Loss: 2.5140\n",
      "Epoch 2, Batch 900, Loss: 2.5053\n",
      "Epoch 2, Batch 1000, Loss: 2.5725\n",
      "Epoch 2, Batch 1100, Loss: 2.4168\n",
      "Epoch 2, Batch 1200, Loss: 2.5372\n",
      "Epoch 2, Batch 1300, Loss: 2.4968\n",
      "Epoch 2, Batch 1400, Loss: 2.4327\n",
      "Epoch 2, Batch 1500, Loss: 2.4168\n",
      "Epoch 2, Batch 1600, Loss: 2.4353\n",
      "Epoch 2, Batch 1700, Loss: 2.5049\n",
      "Epoch 2, Batch 1800, Loss: 2.4066\n",
      "Epoch 2, Batch 1900, Loss: 2.4196\n",
      "Epoch 2, Batch 2000, Loss: 2.4984\n",
      "Epoch 2, Batch 2100, Loss: 2.4325\n",
      "Epoch 2, Batch 2200, Loss: 2.4346\n",
      "Epoch 2, Batch 2300, Loss: 2.3789\n",
      "Epoch 2, Batch 2400, Loss: 2.3549\n",
      "Epoch 2, Batch 2500, Loss: 2.3486\n",
      "Epoch 2, Batch 2600, Loss: 2.3574\n",
      "Epoch 2, Batch 2700, Loss: 2.3758\n",
      "Epoch 2, Batch 2800, Loss: 2.3225\n",
      "Epoch 2, Batch 2900, Loss: 2.3564\n",
      "Epoch 3, Batch 100, Loss: 2.3110\n",
      "Epoch 3, Batch 200, Loss: 2.3842\n",
      "Epoch 3, Batch 300, Loss: 2.3043\n",
      "Epoch 3, Batch 400, Loss: 2.2509\n",
      "Epoch 3, Batch 500, Loss: 2.3242\n",
      "Epoch 3, Batch 600, Loss: 2.3263\n",
      "Epoch 3, Batch 700, Loss: 2.2885\n",
      "Epoch 3, Batch 800, Loss: 2.2138\n",
      "Epoch 3, Batch 900, Loss: 2.2984\n",
      "Epoch 3, Batch 1000, Loss: 2.2256\n",
      "Epoch 3, Batch 1100, Loss: 2.2907\n",
      "Epoch 3, Batch 1200, Loss: 2.2020\n",
      "Epoch 3, Batch 1300, Loss: 2.1957\n",
      "Epoch 3, Batch 1400, Loss: 2.1265\n",
      "Epoch 3, Batch 1500, Loss: 2.3129\n",
      "Epoch 3, Batch 1600, Loss: 2.2292\n",
      "Epoch 3, Batch 1700, Loss: 2.2332\n",
      "Epoch 3, Batch 1800, Loss: 2.1840\n",
      "Epoch 3, Batch 1900, Loss: 2.2488\n",
      "Epoch 3, Batch 2000, Loss: 2.1861\n",
      "Epoch 3, Batch 2100, Loss: 2.0959\n",
      "Epoch 3, Batch 2200, Loss: 2.1704\n",
      "Epoch 3, Batch 2300, Loss: 2.1374\n",
      "Epoch 3, Batch 2400, Loss: 2.2007\n",
      "Epoch 3, Batch 2500, Loss: 2.1547\n",
      "Epoch 3, Batch 2600, Loss: 2.1329\n",
      "Epoch 3, Batch 2700, Loss: 2.1624\n",
      "Epoch 3, Batch 2800, Loss: 2.1543\n",
      "Epoch 3, Batch 2900, Loss: 2.1377\n",
      "Epoch 4, Batch 100, Loss: 2.0901\n",
      "Epoch 4, Batch 200, Loss: 2.1221\n",
      "Epoch 4, Batch 300, Loss: 2.0615\n",
      "Epoch 4, Batch 400, Loss: 2.0323\n",
      "Epoch 4, Batch 500, Loss: 2.0184\n",
      "Epoch 4, Batch 600, Loss: 2.0513\n",
      "Epoch 4, Batch 700, Loss: 2.0175\n",
      "Epoch 4, Batch 800, Loss: 2.0277\n",
      "Epoch 4, Batch 900, Loss: 1.9864\n",
      "Epoch 4, Batch 1000, Loss: 1.9822\n",
      "Epoch 4, Batch 1100, Loss: 2.0145\n",
      "Epoch 4, Batch 1200, Loss: 2.0247\n",
      "Epoch 4, Batch 1300, Loss: 2.0251\n",
      "Epoch 4, Batch 1400, Loss: 1.9590\n",
      "Epoch 4, Batch 1500, Loss: 2.0501\n",
      "Epoch 4, Batch 1600, Loss: 2.0122\n",
      "Epoch 4, Batch 1700, Loss: 2.0012\n",
      "Epoch 4, Batch 1800, Loss: 2.0246\n",
      "Epoch 4, Batch 1900, Loss: 1.9649\n",
      "Epoch 4, Batch 2000, Loss: 2.0110\n",
      "Epoch 4, Batch 2100, Loss: 1.9848\n",
      "Epoch 4, Batch 2200, Loss: 1.9293\n",
      "Epoch 4, Batch 2300, Loss: 1.9814\n",
      "Epoch 4, Batch 2400, Loss: 1.9409\n",
      "Epoch 4, Batch 2500, Loss: 1.9111\n",
      "Epoch 4, Batch 2600, Loss: 2.0061\n",
      "Epoch 4, Batch 2700, Loss: 2.0081\n",
      "Epoch 4, Batch 2800, Loss: 1.9997\n",
      "Epoch 4, Batch 2900, Loss: 1.9027\n",
      "Epoch 5, Batch 100, Loss: 1.8192\n",
      "Epoch 5, Batch 200, Loss: 1.8866\n",
      "Epoch 5, Batch 300, Loss: 1.8087\n",
      "Epoch 5, Batch 400, Loss: 1.8312\n",
      "Epoch 5, Batch 500, Loss: 1.8575\n",
      "Epoch 5, Batch 600, Loss: 1.8181\n",
      "Epoch 5, Batch 700, Loss: 1.8428\n",
      "Epoch 5, Batch 800, Loss: 1.7571\n",
      "Epoch 5, Batch 900, Loss: 1.8191\n",
      "Epoch 5, Batch 1000, Loss: 1.7155\n",
      "Epoch 5, Batch 1100, Loss: 1.8586\n",
      "Epoch 5, Batch 1200, Loss: 1.8874\n",
      "Epoch 5, Batch 1300, Loss: 1.8034\n",
      "Epoch 5, Batch 1400, Loss: 1.8006\n",
      "Epoch 5, Batch 1500, Loss: 1.7830\n",
      "Epoch 5, Batch 1600, Loss: 1.8144\n",
      "Epoch 5, Batch 1700, Loss: 1.7713\n",
      "Epoch 5, Batch 1800, Loss: 1.7634\n",
      "Epoch 5, Batch 1900, Loss: 1.7500\n",
      "Epoch 5, Batch 2000, Loss: 1.7766\n",
      "Epoch 5, Batch 2100, Loss: 1.7954\n",
      "Epoch 5, Batch 2200, Loss: 1.7407\n",
      "Epoch 5, Batch 2300, Loss: 1.8276\n",
      "Epoch 5, Batch 2400, Loss: 1.7799\n",
      "Epoch 5, Batch 2500, Loss: 1.7339\n",
      "Epoch 5, Batch 2600, Loss: 1.8066\n",
      "Epoch 5, Batch 2700, Loss: 1.7336\n",
      "Epoch 5, Batch 2800, Loss: 1.7177\n",
      "Epoch 5, Batch 2900, Loss: 1.7181\n",
      "Epoch 6, Batch 100, Loss: 1.7307\n",
      "Epoch 6, Batch 200, Loss: 1.6075\n",
      "Epoch 6, Batch 300, Loss: 1.6177\n",
      "Epoch 6, Batch 400, Loss: 1.5849\n",
      "Epoch 6, Batch 500, Loss: 1.5540\n",
      "Epoch 6, Batch 600, Loss: 1.6523\n",
      "Epoch 6, Batch 700, Loss: 1.5715\n",
      "Epoch 6, Batch 800, Loss: 1.6504\n",
      "Epoch 6, Batch 900, Loss: 1.5947\n",
      "Epoch 6, Batch 1000, Loss: 1.6047\n",
      "Epoch 6, Batch 1100, Loss: 1.6085\n",
      "Epoch 6, Batch 1200, Loss: 1.6310\n",
      "Epoch 6, Batch 1300, Loss: 1.5782\n",
      "Epoch 6, Batch 1400, Loss: 1.6246\n",
      "Epoch 6, Batch 1500, Loss: 1.6452\n",
      "Epoch 6, Batch 1600, Loss: 1.6288\n",
      "Epoch 6, Batch 1700, Loss: 1.6129\n",
      "Epoch 6, Batch 1800, Loss: 1.6387\n",
      "Epoch 6, Batch 1900, Loss: 1.6594\n",
      "Epoch 6, Batch 2000, Loss: 1.6337\n",
      "Epoch 6, Batch 2100, Loss: 1.5998\n",
      "Epoch 6, Batch 2200, Loss: 1.6229\n",
      "Epoch 6, Batch 2300, Loss: 1.5370\n",
      "Epoch 6, Batch 2400, Loss: 1.6086\n",
      "Epoch 6, Batch 2500, Loss: 1.6495\n",
      "Epoch 6, Batch 2600, Loss: 1.6222\n",
      "Epoch 6, Batch 2700, Loss: 1.5746\n",
      "Epoch 6, Batch 2800, Loss: 1.5389\n",
      "Epoch 6, Batch 2900, Loss: 1.5748\n",
      "Epoch 7, Batch 100, Loss: 1.4492\n",
      "Epoch 7, Batch 200, Loss: 1.4420\n",
      "Epoch 7, Batch 300, Loss: 1.4560\n",
      "Epoch 7, Batch 400, Loss: 1.4745\n",
      "Epoch 7, Batch 500, Loss: 1.4894\n",
      "Epoch 7, Batch 600, Loss: 1.4693\n",
      "Epoch 7, Batch 700, Loss: 1.4787\n",
      "Epoch 7, Batch 800, Loss: 1.4371\n",
      "Epoch 7, Batch 900, Loss: 1.4802\n",
      "Epoch 7, Batch 1000, Loss: 1.4649\n",
      "Epoch 7, Batch 1100, Loss: 1.4395\n",
      "Epoch 7, Batch 1200, Loss: 1.4318\n",
      "Epoch 7, Batch 1300, Loss: 1.4193\n",
      "Epoch 7, Batch 1400, Loss: 1.4858\n",
      "Epoch 7, Batch 1500, Loss: 1.4649\n",
      "Epoch 7, Batch 1600, Loss: 1.4515\n",
      "Epoch 7, Batch 1700, Loss: 1.3800\n",
      "Epoch 7, Batch 1800, Loss: 1.4615\n",
      "Epoch 7, Batch 1900, Loss: 1.4557\n",
      "Epoch 7, Batch 2000, Loss: 1.4284\n",
      "Epoch 7, Batch 2100, Loss: 1.4692\n",
      "Epoch 7, Batch 2200, Loss: 1.4211\n",
      "Epoch 7, Batch 2300, Loss: 1.4312\n",
      "Epoch 7, Batch 2400, Loss: 1.5080\n",
      "Epoch 7, Batch 2500, Loss: 1.4641\n",
      "Epoch 7, Batch 2600, Loss: 1.4122\n",
      "Epoch 7, Batch 2700, Loss: 1.4177\n",
      "Epoch 7, Batch 2800, Loss: 1.4627\n",
      "Epoch 7, Batch 2900, Loss: 1.4622\n",
      "Epoch 8, Batch 100, Loss: 1.3763\n",
      "Epoch 8, Batch 200, Loss: 1.3321\n",
      "Epoch 8, Batch 300, Loss: 1.2889\n",
      "Epoch 8, Batch 400, Loss: 1.3132\n",
      "Epoch 8, Batch 500, Loss: 1.2963\n",
      "Epoch 8, Batch 600, Loss: 1.3266\n",
      "Epoch 8, Batch 700, Loss: 1.2829\n",
      "Epoch 8, Batch 800, Loss: 1.2799\n",
      "Epoch 8, Batch 900, Loss: 1.2979\n",
      "Epoch 8, Batch 1000, Loss: 1.3564\n",
      "Epoch 8, Batch 1100, Loss: 1.2802\n",
      "Epoch 8, Batch 1200, Loss: 1.3764\n",
      "Epoch 8, Batch 1300, Loss: 1.3766\n",
      "Epoch 8, Batch 1400, Loss: 1.2731\n",
      "Epoch 8, Batch 1500, Loss: 1.3780\n",
      "Epoch 8, Batch 1600, Loss: 1.3038\n",
      "Epoch 8, Batch 1700, Loss: 1.2883\n",
      "Epoch 8, Batch 1800, Loss: 1.3295\n",
      "Epoch 8, Batch 1900, Loss: 1.3291\n",
      "Epoch 8, Batch 2000, Loss: 1.3124\n",
      "Epoch 8, Batch 2100, Loss: 1.3382\n",
      "Epoch 8, Batch 2200, Loss: 1.3017\n",
      "Epoch 8, Batch 2300, Loss: 1.3269\n",
      "Epoch 8, Batch 2400, Loss: 1.3167\n",
      "Epoch 8, Batch 2500, Loss: 1.3271\n",
      "Epoch 8, Batch 2600, Loss: 1.3199\n",
      "Epoch 8, Batch 2700, Loss: 1.3530\n",
      "Epoch 8, Batch 2800, Loss: 1.3345\n",
      "Epoch 8, Batch 2900, Loss: 1.3094\n",
      "Epoch 9, Batch 100, Loss: 1.2037\n",
      "Epoch 9, Batch 200, Loss: 1.1885\n",
      "Epoch 9, Batch 300, Loss: 1.2205\n",
      "Epoch 9, Batch 400, Loss: 1.2571\n",
      "Epoch 9, Batch 500, Loss: 1.2202\n",
      "Epoch 9, Batch 600, Loss: 1.1937\n",
      "Epoch 9, Batch 700, Loss: 1.2491\n",
      "Epoch 9, Batch 800, Loss: 1.2048\n",
      "Epoch 9, Batch 900, Loss: 1.2186\n",
      "Epoch 9, Batch 1000, Loss: 1.1826\n",
      "Epoch 9, Batch 1100, Loss: 1.2122\n",
      "Epoch 9, Batch 1200, Loss: 1.2091\n",
      "Epoch 9, Batch 1300, Loss: 1.1820\n",
      "Epoch 9, Batch 1400, Loss: 1.1763\n",
      "Epoch 9, Batch 1500, Loss: 1.1989\n",
      "Epoch 9, Batch 1600, Loss: 1.1904\n",
      "Epoch 9, Batch 1700, Loss: 1.1886\n",
      "Epoch 9, Batch 1800, Loss: 1.2374\n",
      "Epoch 9, Batch 1900, Loss: 1.2259\n",
      "Epoch 9, Batch 2000, Loss: 1.2461\n",
      "Epoch 9, Batch 2100, Loss: 1.2344\n",
      "Epoch 9, Batch 2200, Loss: 1.2148\n",
      "Epoch 9, Batch 2300, Loss: 1.2534\n",
      "Epoch 9, Batch 2400, Loss: 1.2011\n",
      "Epoch 9, Batch 2500, Loss: 1.2018\n",
      "Epoch 9, Batch 2600, Loss: 1.2288\n",
      "Epoch 9, Batch 2700, Loss: 1.2178\n",
      "Epoch 9, Batch 2800, Loss: 1.2223\n",
      "Epoch 9, Batch 2900, Loss: 1.2193\n",
      "Epoch 10, Batch 100, Loss: 1.0889\n",
      "Epoch 10, Batch 200, Loss: 1.1447\n",
      "Epoch 10, Batch 300, Loss: 1.1120\n",
      "Epoch 10, Batch 400, Loss: 1.0837\n",
      "Epoch 10, Batch 500, Loss: 1.1059\n",
      "Epoch 10, Batch 600, Loss: 1.1244\n",
      "Epoch 10, Batch 700, Loss: 1.1060\n",
      "Epoch 10, Batch 800, Loss: 1.0925\n",
      "Epoch 10, Batch 900, Loss: 1.1523\n",
      "Epoch 10, Batch 1000, Loss: 1.1373\n",
      "Epoch 10, Batch 1100, Loss: 1.1097\n",
      "Epoch 10, Batch 1200, Loss: 1.0898\n",
      "Epoch 10, Batch 1300, Loss: 1.0756\n",
      "Epoch 10, Batch 1400, Loss: 1.0891\n",
      "Epoch 10, Batch 1500, Loss: 1.1292\n",
      "Epoch 10, Batch 1600, Loss: 1.0798\n",
      "Epoch 10, Batch 1700, Loss: 1.1218\n",
      "Epoch 10, Batch 1800, Loss: 1.1106\n",
      "Epoch 10, Batch 1900, Loss: 1.1043\n",
      "Epoch 10, Batch 2000, Loss: 1.1213\n",
      "Epoch 10, Batch 2100, Loss: 1.1606\n",
      "Epoch 10, Batch 2200, Loss: 1.1657\n",
      "Epoch 10, Batch 2300, Loss: 1.1319\n",
      "Epoch 10, Batch 2400, Loss: 1.1564\n",
      "Epoch 10, Batch 2500, Loss: 1.1646\n",
      "Epoch 10, Batch 2600, Loss: 1.1587\n",
      "Epoch 10, Batch 2700, Loss: 1.1175\n",
      "Epoch 10, Batch 2800, Loss: 1.1197\n",
      "Epoch 10, Batch 2900, Loss: 1.1221\n",
      "CPU times: total: 15 s\n",
      "Wall time: 1min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Define the dataset class\n",
    "class RatingDataset(Dataset):\n",
    "    \"\"\"Dataset for loading user-item ratings for training\"\"\"\n",
    "    def __init__(self, user_ids, item_ids, ratings):\n",
    "        self.user_ids = torch.tensor(user_ids, dtype=torch.int64)\n",
    "        self.item_ids = torch.tensor(item_ids, dtype=torch.int64)\n",
    "        self.ratings = torch.tensor(ratings, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.user_ids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_ids[idx], self.item_ids[idx], self.ratings[idx]\n",
    "\n",
    "class WideAndDeep(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_dim=20, hidden_layers=[64, 32, 16], dropout_rate=0.2):\n",
    "        super(WideAndDeep, self).__init__()\n",
    "        # Wide part\n",
    "        self.wide = nn.Embedding(num_users + num_items, 1)\n",
    "        # Deep part\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_dim)\n",
    "        self.fc_layers = nn.ModuleList()\n",
    "        input_size = 2 * embedding_dim  # Concatenated user and item embeddings\n",
    "        for hidden_layer in hidden_layers:\n",
    "            self.fc_layers.append(nn.Linear(input_size, hidden_layer))\n",
    "            input_size = hidden_layer\n",
    "        self.fc_layers.append(nn.Linear(input_size, 1))  # Final output layer\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        \n",
    "    def forward(self, user_indices, item_indices):\n",
    "        # Wide part\n",
    "        wide_out = self.wide(user_indices + item_indices)\n",
    "        # Deep part\n",
    "        user_embedding = self.user_embedding(user_indices)\n",
    "        item_embedding = self.item_embedding(item_indices)\n",
    "        x = torch.cat([user_embedding, item_embedding], dim=-1)\n",
    "        for layer in self.fc_layers[:-1]:\n",
    "            x = self.relu(layer(x))\n",
    "            x = self.dropout(x)\n",
    "        deep_out = self.fc_layers[-1](x)\n",
    "        # Combined part\n",
    "        combined_out = wide_out + deep_out\n",
    "        return combined_out.squeeze()\n",
    "\n",
    "# Training function\n",
    "def train_model(model, data_loader, criterion, optimizer, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (users, items, ratings) in enumerate(data_loader):\n",
    "            users = users.to(device)  # Move data to GPU\n",
    "            items = items.to(device)  # Move data to GPU\n",
    "            ratings = ratings.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(users, items)\n",
    "            loss = criterion(outputs, ratings)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            if batch_idx % 100 == 99:\n",
    "                print(f'Epoch {epoch+1}, Batch {batch_idx+1}, Loss: {running_loss / 100:.4f}')\n",
    "                running_loss = 0.0\n",
    "\n",
    "# Prepare data\n",
    "train_data = pd.read_csv(\"cs608_ip_train_v3.csv\")\n",
    "train_data['user_id'] = train_data['user_id'].astype('category').cat.codes\n",
    "train_data['item_id'] = train_data['item_id'].astype('category').cat.codes\n",
    "dataset = RatingDataset(train_data['user_id'], train_data['item_id'], train_data['rating'])\n",
    "\n",
    "# Create DataLoader\n",
    "data_loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "num_users = train_data['user_id'].nunique()\n",
    "num_items = train_data['item_id'].nunique()\n",
    "model = WideAndDeep(num_users, num_items).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, data_loader, criterion, optimizer, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "torch.save(model.state_dict(), \"wide_and_deep.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m     29\u001b[0m         output \u001b[38;5;241m=\u001b[39m model(user, item)\n\u001b[1;32m---> 30\u001b[0m         predictions\u001b[38;5;241m.\u001b[39mextend(\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     31\u001b[0m         actuals\u001b[38;5;241m.\u001b[39mextend(rating\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Calculate evaluation metrics\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "\n",
    "# Load your CSV data\n",
    "data_path = \"./cs608_ip_probe_v3.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "# Assume df has columns 'user_id', 'item_id', which we need to convert to tensor\n",
    "# Also assume that 'ratings' column is your target\n",
    "users = torch.tensor(df[\"user_id\"].values).to(device)\n",
    "items = torch.tensor(df[\"item_id\"].values).to(device)\n",
    "ratings = torch.tensor(df[\"rating\"].values)\n",
    "\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "# Create a data loader for batch processing\n",
    "dataset = TensorDataset(users, items, ratings)\n",
    "data_loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# To store predictions and actual values\n",
    "predictions, actuals = [], []\n",
    "\n",
    "# Evaluate the model\n",
    "for user, item, rating in data_loader:\n",
    "    with torch.no_grad():\n",
    "        output = model(user, item)\n",
    "        predictions.extend(output.cpu().numpy())\n",
    "        actuals.extend(rating.cpu().numpy())\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "predictions = np.array(predictions)\n",
    "actuals = np.array(actuals)\n",
    "rmse = np.sqrt(mean_squared_error(actuals, predictions))\n",
    "accuracy = accuracy_score(actuals, predictions.round())\n",
    "\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def generate_recommendations(model, num_users, num_items, top_k=50):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    recommendations = []\n",
    "\n",
    "    # Iterate over all users\n",
    "    for user_id in tqdm(range(num_users)):\n",
    "        user_tensor = torch.tensor(\n",
    "            [user_id] * num_items, dtype=torch.int64\n",
    "        ).to(device)  # Repeat user ID for each item\n",
    "        item_tensor = torch.tensor(range(num_items), dtype=torch.int64).to(device)  # All item IDs\n",
    "\n",
    "        # Predict scores for all items for this user\n",
    "        with torch.no_grad():\n",
    "            scores = (\n",
    "                model(user_tensor, item_tensor).cpu().numpy()\n",
    "            )  # Get scores and move to CPU\n",
    "\n",
    "        # Get the indices of the top k scores\n",
    "        top_item_indices = scores.argsort()[-top_k:][\n",
    "            ::-1\n",
    "        ]  # Indices of top scoring items\n",
    "\n",
    "        # Append to the list of recommendations\n",
    "        recommendations.append(top_item_indices.tolist())\n",
    "\n",
    "    return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13ad42557658456f928c2646ecbe433f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/21124 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:8\u001b[0m\n",
      "Cell \u001b[1;32mIn[5], line 11\u001b[0m, in \u001b[0;36mgenerate_recommendations\u001b[1;34m(model, num_users, num_items, top_k)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Iterate over all users\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m user_id \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(num_users)):\n\u001b[0;32m      9\u001b[0m     user_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\u001b[43muser_id\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mnum_items\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mint64\u001b[49m\n\u001b[1;32m---> 11\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Repeat user ID for each item\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     item_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(\u001b[38;5;28mrange\u001b[39m(num_items), dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mint64)\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# All item IDs\u001b[39;00m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;66;03m# Predict scores for all items for this user\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import zipfile\n",
    "\n",
    "# Number of users and items\n",
    "num_users = train_data[\"user_id\"].nunique()\n",
    "num_items = train_data[\"item_id\"].nunique()\n",
    "\n",
    "# Generate recommendations for all users\n",
    "top_k_recommendations = generate_recommendations(model, num_users, num_items)\n",
    "\n",
    "with open(\"submission.txt\", \"w\") as file:\n",
    "    for user_recommendations in top_k_recommendations:\n",
    "        file.write(\" \".join(map(str, user_recommendations)) + \"\\n\")\n",
    "\n",
    "# zip the submission file\n",
    "with zipfile.ZipFile('submission.zip', 'w') as file:\n",
    "    file.write('submission.txt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
